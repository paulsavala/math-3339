{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Chapter 2.8 and 2.9: Elastic Net\n",
    "\n",
    "Goal: Understand when Elastic Net combines the benefits of Ridge and Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "### Topics:\n",
    "- Understanding l1_ratio: blending L1 and L2 penalties\n",
    "- Comparing Elastic Net to Ridge and Lasso\n",
    "- Using ElasticNetCV for hyperparameter tuning\n",
    "- Choosing the right regularization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, ElasticNetCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Quick Recap\n",
    "\n",
    "- **Elastic Net** = L1 (Lasso) + L2 (Ridge) combined\n",
    "- **l1_ratio** controls the blend:\n",
    "  - l1_ratio = 0 → Pure Ridge\n",
    "  - l1_ratio = 1 → Pure Lasso\n",
    "  - l1_ratio = 0.5 → Equal mix\n",
    "- When to use: Features are correlated AND you want feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare Auto MPG data (same as previous activity)\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
    "df = pd.read_csv(url, delim_whitespace=True, names=columns, na_values='?')\n",
    "df = df.dropna().drop('car_name', axis=1)\n",
    "\n",
    "X = df.drop('mpg', axis=1)\n",
    "y = df['mpg']\n",
    "\n",
    "# Split and scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Features: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "### 1. Fit ElasticNet with l1_ratio=0.5, alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create ElasticNet with l1_ratio=0.5 and alpha=1\n",
    "enet = ElasticNet(alpha=1, l1_ratio=0.5, random_state=42)\n",
    "\n",
    "# Step 2: Fit on scaled training data\n",
    "enet.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 3: Display coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Elastic Net (0.5)': enet.coef_\n",
    "})\n",
    "\n",
    "print(f\"Elastic Net R² on test: {enet.score(X_test_scaled, y_test):.4f}\")\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### 2. How many coefficients are zero? Compare to Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Lasso for comparison\n",
    "lasso = Lasso(alpha=1, random_state=42)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Count zeros\n",
    "enet_zeros = (enet.coef_ == 0).sum()\n",
    "lasso_zeros = (lasso.coef_ == 0).sum()\n",
    "\n",
    "print(f\"Elastic Net (l1_ratio=0.5): {enet_zeros} zero coefficients\")\n",
    "print(f\"Lasso: {lasso_zeros} zero coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "**Your observation:** Does Elastic Net eliminate as many features as Lasso?\n",
    "\n",
    "(Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### 3. Fit with l1_ratio=0.1 (more Ridge-like) - fewer zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create ElasticNet with l1_ratio=0.1\n",
    "\n",
    "\n",
    "# Step 2: Fit and count zeros\n",
    "\n",
    "\n",
    "# Step 3: Print results\n",
    "print(f\"Elastic Net (l1_ratio=0.1) R²: {enet_01.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"Zero coefficients: {(enet_01.coef_ == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### 4. Fit with l1_ratio=0.9 (more Lasso-like) - more zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create ElasticNet with l1_ratio=0.9\n",
    "\n",
    "\n",
    "# Step 2: Fit and count zeros\n",
    "\n",
    "\n",
    "# Step 3: Print results\n",
    "print(f\"Elastic Net (l1_ratio=0.9) R²: {enet_09.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"Zero coefficients: {(enet_09.coef_ == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "**Your observation:** Summarize the relationship between l1_ratio and number of zero coefficients:\n",
    "\n",
    "| l1_ratio | Zero Coefficients | R² |\n",
    "|----------|-------------------|----|\n",
    "| 0.1 (Ridge-like) | | |\n",
    "| 0.5 (balanced) | | |\n",
    "| 0.9 (Lasso-like) | | |\n",
    "\n",
    "(Fill in the table with your results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### 5. Use ElasticNetCV to find optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNetCV tunes both alpha and l1_ratio\n",
    "l1_ratios = [0.1, 0.5, 0.7, 0.9, 0.95, 0.99]\n",
    "\n",
    "enet_cv = ElasticNetCV(l1_ratio=l1_ratios, cv=5, random_state=42)\n",
    "enet_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best alpha: {enet_cv.alpha_:.4f}\")\n",
    "print(f\"Best l1_ratio: {enet_cv.l1_ratio_}\")\n",
    "print(f\"Test R²: {enet_cv.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What features remain?\n",
    "print(\"\\nFeatures selected by ElasticNetCV:\")\n",
    "for feat, coef in zip(X.columns, enet_cv.coef_):\n",
    "    status = \"KEPT\" if coef != 0 else \"eliminated\"\n",
    "    print(f\"  {feat}: {coef:.4f} ({status})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### 6. Compare R² scores: OLS vs Ridge vs Lasso vs Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all models with CV-tuned parameters\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "\n",
    "# OLS\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Ridge CV\n",
    "ridge_cv = RidgeCV(cv=5)\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Lasso CV\n",
    "lasso_cv = LassoCV(cv=5, random_state=42)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Final comparison\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['OLS', 'Ridge', 'Lasso', 'Elastic Net'],\n",
    "    'Test R²': [\n",
    "        ols.score(X_test_scaled, y_test),\n",
    "        ridge_cv.score(X_test_scaled, y_test),\n",
    "        lasso_cv.score(X_test_scaled, y_test),\n",
    "        enet_cv.score(X_test_scaled, y_test)\n",
    "    ],\n",
    "    'Non-zero Features': [\n",
    "        len(X.columns),\n",
    "        len(X.columns),  # Ridge never sets to 0\n",
    "        (lasso_cv.coef_ != 0).sum(),\n",
    "        (enet_cv.coef_ != 0).sum()\n",
    "    ]\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "**Your recommendation:** Based on this comparison, which model would you choose for this dataset? Consider:\n",
    "- Performance (R²)\n",
    "- Simplicity (number of features)\n",
    "- Interpretability\n",
    "\n",
    "(Write your recommendation here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Summary: When to Use Each Method\n",
    "\n",
    "| Method | Best When... | Key Characteristic |\n",
    "|--------|-------------|--------------------|\n",
    "| **OLS** | Features are independent, no overfitting concern | No regularization |\n",
    "| **Ridge** | Features are correlated, want to keep all features | Shrinks but keeps all |\n",
    "| **Lasso** | Want automatic feature selection, sparse model | Sets some to zero |\n",
    "| **Elastic Net** | Features are correlated AND want selection | Best of both worlds |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Discussion Question\n",
    "\n",
    "A colleague says \"Just use Elastic Net for everything since it combines Ridge and Lasso.\" Do you agree? What are the trade-offs?\n",
    "\n",
    "(Discuss with a neighbor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

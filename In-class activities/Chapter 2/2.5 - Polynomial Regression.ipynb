{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Chapter 2.5: Polynomial Regression\n",
    "\n",
    "Goal: Create polynomial features and select the optimal degree to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "### Topics:\n",
    "- Creating polynomial features with `PolynomialFeatures`\n",
    "- Comparing models of different degrees\n",
    "- Identifying overfitting (train-val gap)\n",
    "- Selecting optimal polynomial degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Quick Recap\n",
    "\n",
    "- **Polynomial features** turn X into [X, X², X³, ...] to capture curves\n",
    "- Higher degree = more flexible, but risk of **overfitting**\n",
    "- Overfitting: High training score, low validation score\n",
    "- Use validation set to choose the best degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load diamonds dataset\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "\n",
    "# Use a subset for faster training\n",
    "diamonds_sample = diamonds.sample(n=5000, random_state=42)\n",
    "\n",
    "# We'll predict price from carat (single feature for visualization)\n",
    "X = diamonds_sample[['carat']].values\n",
    "y = diamonds_sample['price'].values\n",
    "\n",
    "# Three-way split: 60% train, 20% val, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "### 1. Create degree-2 polynomial features from `carat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create PolynomialFeatures with degree=2\n",
    "poly2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Step 2: Fit on training data and transform train, val, test\n",
    "X_train_poly2 = poly2.fit_transform(X_train)\n",
    "X_val_poly2 = poly2.transform(X_val)\n",
    "X_test_poly2 = poly2.transform(X_test)\n",
    "\n",
    "# See what features were created\n",
    "print(f\"Original features: {X_train.shape[1]}\")\n",
    "print(f\"Polynomial features: {X_train_poly2.shape[1]}\")\n",
    "print(f\"Feature names: {poly2.get_feature_names_out()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### 2. Fit linear regression on polynomial features, calculate train and val R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fit LinearRegression on polynomial features\n",
    "model_poly2 = LinearRegression()\n",
    "model_poly2.fit(X_train_poly2, y_train)\n",
    "\n",
    "# Step 2: Calculate R² on train and validation\n",
    "train_r2 = model_poly2.score(X_train_poly2, y_train)\n",
    "val_r2 = model_poly2.score(X_val_poly2, y_val)\n",
    "\n",
    "print(f\"Degree 2 - Train R²: {train_r2:.4f}, Val R²: {val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### 3. Repeat for degree 3, 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree 3\n",
    "# Step 1: Create PolynomialFeatures(degree=3)\n",
    "# Step 2: Transform data\n",
    "# Step 3: Fit model and calculate scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### 4. Create a table showing degree, train R², val R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do this systematically with a loop\n",
    "results = []\n",
    "\n",
    "for degree in range(1, 8):  # Degrees 1 through 7\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_p = poly.fit_transform(X_train)\n",
    "    X_val_p = poly.transform(X_val)\n",
    "    \n",
    "    # Fit model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_p, y_train)\n",
    "    \n",
    "    # Calculate scores\n",
    "    train_score = model.score(X_train_p, y_train)\n",
    "    val_score = model.score(X_val_p, y_val)\n",
    "    \n",
    "    results.append({\n",
    "        'Degree': degree,\n",
    "        'Train R²': train_score,\n",
    "        'Val R²': val_score,\n",
    "        'Gap': train_score - val_score\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### 5. Which degree shows the largest train-val gap (overfitting)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['Degree'], results_df['Train R²'], 'o-', label='Train R²')\n",
    "plt.plot(results_df['Degree'], results_df['Val R²'], 's-', label='Validation R²')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('Train vs Validation R² by Polynomial Degree')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "**Your observation:** Which degree has the largest gap between train and val R²? This is a sign of overfitting.\n",
    "\n",
    "(Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### 6. Which degree would you choose and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the degree with highest validation R²\n",
    "best_degree = results_df.loc[results_df['Val R²'].idxmax(), 'Degree']\n",
    "best_val_r2 = results_df['Val R²'].max()\n",
    "\n",
    "print(f\"Best degree based on validation: {best_degree}\")\n",
    "print(f\"Validation R² at best degree: {best_val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "**Your recommendation:** Which degree would you choose for this model? Explain your reasoning.\n",
    "\n",
    "(Write your answer here - consider both validation performance AND simplicity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Bonus: Visualize the polynomial fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smooth line for plotting\n",
    "X_line = np.linspace(X_train.min(), X_train.max(), 100).reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X_val, y_val, alpha=0.3, label='Validation Data')\n",
    "\n",
    "for degree in [1, 2, 3, 5]:\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_p = poly.fit_transform(X_train)\n",
    "    X_line_p = poly.transform(X_line)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_p, y_train)\n",
    "    y_line = model.predict(X_line_p)\n",
    "    \n",
    "    plt.plot(X_line, y_line, label=f'Degree {degree}')\n",
    "\n",
    "plt.xlabel('Carat')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.title('Polynomial Regression Fits of Different Degrees')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Discussion Question\n",
    "\n",
    "If you were presenting this model to a stakeholder, would you prefer degree 2 with R²=0.85 or degree 5 with R²=0.87? Why?\n",
    "\n",
    "(Discuss with a neighbor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

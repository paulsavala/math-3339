{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Chapter 2.3: Evaluation Metrics\n",
    "\n",
    "Goal: Calculate and interpret MSE, MAE, RMSE, and R² to understand model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "### Topics:\n",
    "- Computing metrics manually and with sklearn\n",
    "- Understanding when to use MSE vs MAE\n",
    "- Interpreting R² as variance explained\n",
    "- How outliers affect different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Quick Recap\n",
    "\n",
    "- **MSE**: Average of squared errors - penalizes large errors heavily\n",
    "- **RMSE**: Square root of MSE - same units as target variable\n",
    "- **MAE**: Average of absolute errors - robust to outliers\n",
    "- **R²**: Proportion of variance explained (0 to 1, higher is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Diamonds dataset\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll predict price from carat\n",
    "X = diamonds[['carat']]\n",
    "y = diamonds['price']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"Model fitted. Test set size: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "### 1. Fit regression: carat → price, calculate predictions\n",
    "\n",
    "(Already done above - just verify the predictions look reasonable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at first 5 actual vs predicted values\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test.values[:5],\n",
    "    'Predicted': y_pred[:5],\n",
    "    'Error': y_test.values[:5] - y_pred[:5]\n",
    "})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### 2. Calculate MSE by hand: `((y_true - y_pred)**2).mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the errors (residuals)\n",
    "errors = y_test - y_pred\n",
    "\n",
    "# Step 2: Square the errors\n",
    "\n",
    "\n",
    "# Step 3: Take the mean\n",
    "\n",
    "\n",
    "print(f\"MSE (by hand): {mse_manual:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### 3. Calculate MAE by hand: `(abs(y_true - y_pred)).mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Take absolute value of errors\n",
    "\n",
    "\n",
    "# Step 2: Take the mean\n",
    "\n",
    "\n",
    "print(f\"MAE (by hand): {mae_manual:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### 4. Use sklearn functions to verify your calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE, MAE, and R² using sklearn\n",
    "mse_sklearn = mean_squared_error(y_test, y_pred)\n",
    "mae_sklearn = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mse_sklearn)\n",
    "\n",
    "print(f\"MSE (sklearn): {mse_sklearn:.2f}\")\n",
    "print(f\"MAE (sklearn): {mae_sklearn:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "**Question:** Which metric is most interpretable for this problem? Why?\n",
    "\n",
    "(Write your answer here - hint: RMSE is in the same units as price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### 5. Add 5 extreme outliers to y_test, recalculate MSE vs MAE - which changed more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of y_test with outliers\n",
    "y_test_outliers = y_test.copy()\n",
    "\n",
    "# Add 5 extreme outliers (errors of $50,000)\n",
    "outlier_indices = y_test_outliers.index[:5]\n",
    "y_pred_outliers = y_pred.copy()\n",
    "y_pred_outliers[:5] = y_pred_outliers[:5] + 50000  # Predictions are way off\n",
    "\n",
    "# Calculate new metrics with outliers\n",
    "mse_outliers = mean_squared_error(y_test, y_pred_outliers)\n",
    "mae_outliers = mean_absolute_error(y_test, y_pred_outliers)\n",
    "\n",
    "print(\"Original metrics:\")\n",
    "print(f\"  MSE: {mse_sklearn:,.2f}\")\n",
    "print(f\"  MAE: {mae_sklearn:,.2f}\")\n",
    "\n",
    "print(\"\\nWith 5 outliers:\")\n",
    "print(f\"  MSE: {mse_outliers:,.2f}\")\n",
    "print(f\"  MAE: {mae_outliers:,.2f}\")\n",
    "\n",
    "print(\"\\nPercent change:\")\n",
    "print(f\"  MSE changed by: {(mse_outliers - mse_sklearn) / mse_sklearn * 100:.1f}%\")\n",
    "print(f\"  MAE changed by: {(mae_outliers - mae_sklearn) / mae_sklearn * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "**Your interpretation:** Which metric changed more? Why does this happen?\n",
    "\n",
    "(Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### 6. Calculate Adjusted R² manually using the formula\n",
    "\n",
    "Adjusted R² penalizes adding features that don't help:\n",
    "\n",
    "$$\\text{Adjusted } R^2 = 1 - \\frac{(1 - R^2)(n - 1)}{n - p - 1}$$\n",
    "\n",
    "Where:\n",
    "- n = number of samples\n",
    "- p = number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Adjusted R²\n",
    "n = len(y_test)  # number of samples\n",
    "p = X_test.shape[1]  # number of features\n",
    "\n",
    "# Apply the formula\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "print(f\"R²: {r2:.6f}\")\n",
    "print(f\"Adjusted R²: {adjusted_r2:.6f}\")\n",
    "print(f\"\\nDifference: {r2 - adjusted_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "**Question:** Why is Adjusted R² slightly lower than R²? When would this difference be larger?\n",
    "\n",
    "(Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Metric | Value | Interpretation |\n",
    "|--------|-------|----------------|\n",
    "| MSE | | Sensitive to large errors |\n",
    "| RMSE | | Average error in dollars |\n",
    "| MAE | | Robust to outliers |\n",
    "| R² | | Variance explained |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

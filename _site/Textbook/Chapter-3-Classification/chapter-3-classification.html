<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Chapter 3: Classification Models – MATH 3339: Introduction to Data Science with LLMs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles/textbook-nav.css">
</head>

<body class="quarto-light">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#ch3-resources" id="toc-ch3-resources" class="nav-link active" data-scroll-target="#ch3-resources">Chapter Resources</a></li>
  <li><a href="#ch3-intro" id="toc-ch3-intro" class="nav-link" data-scroll-target="#ch3-intro">Introduction</a></li>
  <li><a href="#ch3-1" id="toc-ch3-1" class="nav-link" data-scroll-target="#ch3-1">1. Machine Learning Paradigms: Supervised vs Unsupervised Learning</a>
  <ul class="collapse">
  <li><a href="#ch3-1-1" id="toc-ch3-1-1" class="nav-link" data-scroll-target="#ch3-1-1">1.1 Supervised Learning: Learning from Labels</a></li>
  <li><a href="#ch3-1-2" id="toc-ch3-1-2" class="nav-link" data-scroll-target="#ch3-1-2">1.2 Unsupervised Learning: Finding Patterns Without Labels</a></li>
  <li><a href="#ch3-1-3" id="toc-ch3-1-3" class="nav-link" data-scroll-target="#ch3-1-3">1.3 When to Use Each Paradigm</a></li>
  </ul></li>
  <li><a href="#ch3-2" id="toc-ch3-2" class="nav-link" data-scroll-target="#ch3-2">2. Classification vs Regression: What’s Different?</a>
  <ul class="collapse">
  <li><a href="#ch3-2-1" id="toc-ch3-2-1" class="nav-link" data-scroll-target="#ch3-2-1">2.1 The Fundamental Difference</a></li>
  <li><a href="#ch3-1-2" id="toc-ch3-1-2" class="nav-link" data-scroll-target="#ch3-1-2">2.2 Types of Classification Problems</a></li>
  <li><a href="#ch3-1-3" id="toc-ch3-1-3" class="nav-link" data-scroll-target="#ch3-1-3">2.3 Why We Can’t Use Linear Regression</a></li>
  </ul></li>
  <li><a href="#ch3-3" id="toc-ch3-3" class="nav-link" data-scroll-target="#ch3-3">3. Logistic Regression: The Foundation</a>
  <ul class="collapse">
  <li><a href="#ch3-2-1" id="toc-ch3-2-1" class="nav-link" data-scroll-target="#ch3-2-1">3.1 From Linear to Logistic</a></li>
  <li><a href="#ch3-2-2" id="toc-ch3-2-2" class="nav-link" data-scroll-target="#ch3-2-2">3.2 Fitting Logistic Regression</a></li>
  <li><a href="#ch3-3-3" id="toc-ch3-3-3" class="nav-link" data-scroll-target="#ch3-3-3">3.3 Interpreting Coefficients</a></li>
  </ul></li>
  <li><a href="#ch3-4" id="toc-ch3-4" class="nav-link" data-scroll-target="#ch3-4">4. The Confusion Matrix: Understanding Errors</a>
  <ul class="collapse">
  <li><a href="#ch3-3-1" id="toc-ch3-3-1" class="nav-link" data-scroll-target="#ch3-3-1">4.1 What Is a Confusion Matrix?</a></li>
  <li><a href="#ch3-3-2" id="toc-ch3-3-2" class="nav-link" data-scroll-target="#ch3-3-2">4.2 Computing Metrics from the Confusion Matrix</a></li>
  <li><a href="#ch3-3-3" id="toc-ch3-3-3" class="nav-link" data-scroll-target="#ch3-3-3">4.3 When Each Metric Matters</a></li>
  </ul></li>
  <li><a href="#ch3-5" id="toc-ch3-5" class="nav-link" data-scroll-target="#ch3-5">5. Decision Trees: Interpretable Non-Linear Classifiers</a>
  <ul class="collapse">
  <li><a href="#ch3-4-1" id="toc-ch3-4-1" class="nav-link" data-scroll-target="#ch3-4-1">5.1 How Decision Trees Work</a></li>
  <li><a href="#ch3-4-2" id="toc-ch3-4-2" class="nav-link" data-scroll-target="#ch3-4-2">5.2 Splitting Criteria: Gini vs Entropy</a></li>
  <li><a href="#ch3-4-3" id="toc-ch3-4-3" class="nav-link" data-scroll-target="#ch3-4-3">5.3 Controlling Tree Depth: The Overfitting Problem</a></li>
  <li><a href="#ch3-5-4" id="toc-ch3-5-4" class="nav-link" data-scroll-target="#ch3-5-4">5.4 Feature Importance</a></li>
  </ul></li>
  <li><a href="#ch3-6" id="toc-ch3-6" class="nav-link" data-scroll-target="#ch3-6">6. Random Forests: Ensemble Power</a>
  <ul class="collapse">
  <li><a href="#ch3-5-1" id="toc-ch3-5-1" class="nav-link" data-scroll-target="#ch3-5-1">6.1 Why Ensembles Work</a></li>
  <li><a href="#ch3-5-2" id="toc-ch3-5-2" class="nav-link" data-scroll-target="#ch3-5-2">6.2 Fitting a Random Forest</a></li>
  <li><a href="#ch3-5-3" id="toc-ch3-5-3" class="nav-link" data-scroll-target="#ch3-5-3">6.3 Feature Importance in Random Forests</a></li>
  <li><a href="#ch3-6-4" id="toc-ch3-6-4" class="nav-link" data-scroll-target="#ch3-6-4">6.4 Hyperparameter Tuning</a></li>
  </ul></li>
  <li><a href="#ch3-7" id="toc-ch3-7" class="nav-link" data-scroll-target="#ch3-7">7. Support Vector Machines: Maximum Margin Classifiers</a>
  <ul class="collapse">
  <li><a href="#ch3-7-1" id="toc-ch3-7-1" class="nav-link" data-scroll-target="#ch3-7-1">7.1 The Margin Concept</a></li>
  <li><a href="#ch3-7-2" id="toc-ch3-7-2" class="nav-link" data-scroll-target="#ch3-7-2">7.2 The Kernel Trick</a></li>
  <li><a href="#ch3-6-3" id="toc-ch3-6-3" class="nav-link" data-scroll-target="#ch3-6-3">6.3 Visualizing SVM Decision Boundaries</a></li>
  <li><a href="#ch3-7-4" id="toc-ch3-7-4" class="nav-link" data-scroll-target="#ch3-7-4">7.4 When to Use SVMs</a></li>
  </ul></li>
  <li><a href="#ch3-8" id="toc-ch3-8" class="nav-link" data-scroll-target="#ch3-8">8. k-Nearest Neighbors: Simple but Powerful</a>
  <ul class="collapse">
  <li><a href="#ch3-7-1" id="toc-ch3-7-1" class="nav-link" data-scroll-target="#ch3-7-1">8.1 The k-NN Algorithm</a></li>
  <li><a href="#ch3-7-2" id="toc-ch3-7-2" class="nav-link" data-scroll-target="#ch3-7-2">8.2 Choosing k: The Bias-Variance Tradeoff Again</a></li>
  <li><a href="#ch3-8-3" id="toc-ch3-8-3" class="nav-link" data-scroll-target="#ch3-8-3">8.3 Distance Metrics: How Do We Measure “Closeness”?</a></li>
  <li><a href="#ch3-7-4" id="toc-ch3-7-4" class="nav-link" data-scroll-target="#ch3-7-4">8.4 Mixing Metrics: Different Features Need Different Distances</a></li>
  <li><a href="#ch3-7-5" id="toc-ch3-7-5" class="nav-link" data-scroll-target="#ch3-7-5">8.5 When to Use k-NN</a></li>
  </ul></li>
  <li><a href="#ch3-9" id="toc-ch3-9" class="nav-link" data-scroll-target="#ch3-9">9. ROC Curves and AUC: Comparing Models</a>
  <ul class="collapse">
  <li><a href="#ch3-9-1" id="toc-ch3-9-1" class="nav-link" data-scroll-target="#ch3-9-1">9.1 The ROC Curve</a></li>
  <li><a href="#ch3-8-2" id="toc-ch3-8-2" class="nav-link" data-scroll-target="#ch3-8-2">9.2 Comparing Multiple Models with ROC</a></li>
  <li><a href="#ch3-8-3" id="toc-ch3-8-3" class="nav-link" data-scroll-target="#ch3-8-3">9.3 When to Use ROC/AUC</a></li>
  </ul></li>
  <li><a href="#ch3-10" id="toc-ch3-10" class="nav-link" data-scroll-target="#ch3-10">10. Class Imbalance: The Real-World Problem</a>
  <ul class="collapse">
  <li><a href="#ch3-9-1" id="toc-ch3-9-1" class="nav-link" data-scroll-target="#ch3-9-1">10.1 Why Class Imbalance Matters</a></li>
  <li><a href="#ch3-9-2" id="toc-ch3-9-2" class="nav-link" data-scroll-target="#ch3-9-2">10.2 Detecting Class Imbalance</a></li>
  <li><a href="#ch3-9-3" id="toc-ch3-9-3" class="nav-link" data-scroll-target="#ch3-9-3">10.3 Handling Class Imbalance: Class Weights</a></li>
  <li><a href="#ch3-9-4" id="toc-ch3-9-4" class="nav-link" data-scroll-target="#ch3-9-4">10.4 Handling Class Imbalance: Resampling</a></li>
  <li><a href="#ch3-9-5" id="toc-ch3-9-5" class="nav-link" data-scroll-target="#ch3-9-5">10.5 Choosing Metrics for Imbalanced Data</a></li>
  </ul></li>
  <li><a href="#ch3-10" id="toc-ch3-10" class="nav-link" data-scroll-target="#ch3-10">11. Comparing All Models: A Practical Guide</a>
  <ul class="collapse">
  <li><a href="#ch3-10-1" id="toc-ch3-10-1" class="nav-link" data-scroll-target="#ch3-10-1">11.1 Model Selection Framework</a></li>
  <li><a href="#ch3-10-2" id="toc-ch3-10-2" class="nav-link" data-scroll-target="#ch3-10-2">11.2 Complete Model Comparison</a></li>
  <li><a href="#ch3-10-3" id="toc-ch3-10-3" class="nav-link" data-scroll-target="#ch3-10-3">11.3 Visualizing Model Performance</a></li>
  <li><a href="#ch3-10-4" id="toc-ch3-10-4" class="nav-link" data-scroll-target="#ch3-10-4">11.4 The Importance of Context</a></li>
  </ul></li>
  <li><a href="#ch3-summary" id="toc-ch3-summary" class="nav-link" data-scroll-target="#ch3-summary">Summary</a></li>
  <li><a href="#ch3-practice" id="toc-ch3-practice" class="nav-link" data-scroll-target="#ch3-practice">Practice Exercises</a></li>
  <li><a href="#ch3-additional-resources" id="toc-ch3-additional-resources" class="nav-link" data-scroll-target="#ch3-additional-resources">Additional Resources</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<nav class="chapter-nav" aria-label="Textbook navigation">
  <a class="chapter-nav__link" href="https://paulsavala.github.io/math-3339-intro-data-science-with-llms/" aria-label="Course home" title="Course home">
    <i class="bi bi-house"></i>
  </a>
  <a class="chapter-nav__link" href="../table-of-contents.html" aria-label="Table of contents" title="Table of contents">
    <i class="bi bi-list"></i>
  </a>
</nav>

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Chapter 3: Classification Models</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="ch3-resources" class="level2">
<h2 class="anchored" data-anchor-id="ch3-resources">Chapter Resources</h2>
<p><strong>Related Assignments:</strong></p>
<ul>
<li><a href="../../Assignments/Chapter 3 - Classification/chapter-3-homework.html">Chapter 3 Homework</a></li>
</ul>
<hr>
</section>
<section id="ch3-intro" class="level2">
<h2 class="anchored" data-anchor-id="ch3-intro">Introduction</h2>
<p>You’ve spent weeks learning regression—predicting continuous values like house prices or income. But what happens when you need to predict categories instead? Will this customer churn or stay? Is this email spam or legitimate? Does this patient have the disease or not?</p>
<p>This is classification, and it’s everywhere. Classification powers the spam filter in your email, the fraud detection on your credit card, the recommendation systems suggesting what you should watch next, and the medical diagnostics helping doctors identify diseases. If you’ve ever wondered “will this happen or not?” or “which category does this belong to?”—that’s a classification problem.</p>
<p>Just like with regression, there isn’t one “best” classification algorithm. Logistic regression is fast and interpretable. Decision trees are easy to explain to non-technical stakeholders. Random forests are robust and powerful. Support vector machines handle high-dimensional data elegantly. k-Nearest neighbors is beautifully simple but computationally expensive. Each has strengths, weaknesses, and situations where it shines.</p>
<p>And the evaluation is completely different from regression. You can’t use R² or MSE. Instead, you’ll need to navigate confusion matrices, ROC curves, precision-recall tradeoffs, and decide whether false positives or false negatives are more costly for your specific problem. A model that’s 99% accurate might be completely useless if you’re trying to detect a rare disease.</p>
<p>This chapter will teach you not just how to fit classification models, but how to think like a data scientist choosing between them. You’ll learn:</p>
<ul>
<li>How five major classification algorithms work and when to use each</li>
<li>How to interpret confusion matrices and choose the right metrics</li>
<li>The precision-recall tradeoff and why it matters</li>
<li>How to handle imbalanced datasets (the most common real-world scenario)</li>
<li>How to visualize decision boundaries to understand what your model is actually doing</li>
<li>How to use ROC curves to compare model performance</li>
</ul>
<p>Let’s jump in.</p>
<hr>
</section>
<section id="ch3-1" class="level2">
<h2 class="anchored" data-anchor-id="ch3-1">1. Machine Learning Paradigms: Supervised vs Unsupervised Learning</h2>
<p>Before we dive into specific classification algorithms, let’s step back and understand a fundamental distinction in machine learning: supervised versus unsupervised learning. Understanding this paradigm will help you recognize when classification is the right approach and when other techniques might be more appropriate.</p>
<section id="ch3-1-1" class="level3">
<h3 class="anchored" data-anchor-id="ch3-1-1">1.1 Supervised Learning: Learning from Labels</h3>
<p><strong>Supervised learning</strong> is what we’ve been doing throughout this course: you give the model input data (features) and the correct answers (labels/targets), and it learns to predict the right answer for new inputs.</p>
<div id="8fc602d6" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Spotify data (supervised classification example)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>spotify_df <span class="op">=</span> pd.read_csv(<span class="st">'../data/spotify.csv'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># We have features (X) and a target (y)</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's predict whether a song will be popular (binary classification)</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> spotify_df[[<span class="st">'danceability'</span>, <span class="st">'energy'</span>, <span class="st">'valence'</span>, <span class="st">'tempo'</span>]]</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (spotify_df[<span class="st">'popularity'</span>] <span class="op">&gt;</span> <span class="dv">50</span>).astype(<span class="bu">int</span>)  <span class="co"># 1 if popular, 0 if not</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Supervised learning setup:"</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Features (X) shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Target (y) shape: </span><span class="sc">{</span>y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Class distribution: </span><span class="sc">{</span>y<span class="sc">.</span>value_counts()<span class="sc">.</span>to_dict()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">First few rows of features:"</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>X.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Supervised learning setup:
Features (X) shape: (42663, 4)
Target (y) shape: (42663,)
Class distribution: {0: 33578, 1: 9085}

First few rows of features:</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">danceability</th>
<th data-quarto-table-cell-role="th">energy</th>
<th data-quarto-table-cell-role="th">valence</th>
<th data-quarto-table-cell-role="th">tempo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>0.792</td>
<td>0.7310</td>
<td>0.8380</td>
<td>113.007</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>0.418</td>
<td>0.3280</td>
<td>0.6800</td>
<td>164.315</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>0.199</td>
<td>0.0957</td>
<td>0.0391</td>
<td>77.722</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>0.862</td>
<td>0.5210</td>
<td>0.3730</td>
<td>154.983</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>0.168</td>
<td>0.1960</td>
<td>0.0554</td>
<td>83.898</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cc392c63" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Corresponding targets (1 = popular, 0 = not popular):"</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>y.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Corresponding targets (1 = popular, 0 = not popular):</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>0    0
1    0
2    0
3    1
4    0
Name: popularity, dtype: int64</code></pre>
</div>
</div>
<p>The key to supervised learning is that we have labels. We know what the correct answer is for each training example. The model learns by comparing its predictions to the true labels and adjusting to get closer.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Both regression (from Chapter 2) and classification are supervised learning tasks. The difference is that regression predicts continuous values while classification predicts discrete categories. But both require labeled training data.</p>
</div>
</div>
</section>
<section id="ch3-1-2" class="level3">
<h3 class="anchored" data-anchor-id="ch3-1-2">1.2 Unsupervised Learning: Finding Patterns Without Labels</h3>
<p><strong>Unsupervised learning</strong> is different: you only have input data (X), no labels (y). The model’s job is to find patterns, structure, or groupings in the data on its own.</p>
<p>For example, we can use unsupervised learning to find natural groupings of flowers based on their measurements. We don’t tell the model what the groupings should be—it discovers them on its own. This is what clustering algorithms like KMeans do.</p>
<div id="dc69cfaf" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Using Iris dataset, but ignoring the labels (species)</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Can we find natural groupings of flowers based on their measurements?</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> load_iris(as_frame<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>iris_df <span class="op">=</span> iris.frame</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>X_unlabeled <span class="op">=</span> iris_df[[<span class="st">'petal length (cm)'</span>, <span class="st">'petal width (cm)'</span>]]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># K-Means clustering: find groups in the data</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">1</span>, n_init<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> kmeans.fit_predict(X_unlabeled)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the clusters</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_unlabeled[<span class="st">'petal length (cm)'</span>], X_unlabeled[<span class="st">'petal width (cm)'</span>],</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>            c<span class="op">=</span>clusters, cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>plt.scatter(kmeans.cluster_centers_[:, <span class="dv">0</span>], kmeans.cluster_centers_[:, <span class="dv">1</span>],</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>            c<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'X'</span>, s<span class="op">=</span><span class="dv">200</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Centroids'</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Petal Length (cm)'</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Petal Width (cm)'</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'K-Means Clustering: Discovering Flower Groups (Unsupervised)'</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-4-output-1.png" width="812" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Notice what happened: we didn’t tell the model which flowers were which species. We just said “find 3 groups” and it discovered natural clusters based on petal measurements alone.</p>
<p>Common unsupervised learning tasks include:</p>
<ul>
<li><strong>Clustering:</strong> Grouping similar items together (customer segmentation, document clustering)</li>
<li><strong>Dimensionality Reduction:</strong> Reducing many features to a few key ones (PCA, t-SNE for visualization)</li>
<li><strong>Anomaly Detection:</strong> Finding unusual examples (fraud detection, manufacturing defects)</li>
</ul>
</section>
<section id="ch3-1-3" class="level3">
<h3 class="anchored" data-anchor-id="ch3-1-3">1.3 When to Use Each Paradigm</h3>
<p>Use <strong>supervised learning</strong> when:</p>
<ul>
<li>You have labeled data (you know the correct answers)</li>
<li>You want to predict something specific</li>
<li>You can define success (accuracy, error rate, etc.)</li>
</ul>
<p>Use <strong>unsupervised learning</strong> when:</p>
<ul>
<li>You don’t have labels (or getting labels is too expensive)</li>
<li>You want to explore data structure</li>
<li>You’re looking for patterns you don’t know exist yet</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Most real-world applications use supervised learning, because prediction is usually the goal. Unsupervised learning is powerful for exploration and preprocessing, but harder to evaluate (how do you know if clusters are “good”?). Unsupervised learning is often used as an intermediate step to generate new features, which are then used in a supervised learning model.</p>
</div>
</div>
<p>For the rest of this chapter, we’ll focus on supervised classification, since that’s where you’ll spend most of your time as a data scientist.</p>
<hr>
</section>
</section>
<section id="ch3-2" class="level2">
<h2 class="anchored" data-anchor-id="ch3-2">2. Classification vs Regression: What’s Different?</h2>
<section id="ch3-2-1" class="level3">
<h3 class="anchored" data-anchor-id="ch3-2-1">2.1 The Fundamental Difference</h3>
<p>In regression, we predict a continuous value. In classification, we predict a category. Seems simple, but this fundamental difference changes everything about how we build, train, and evaluate models.</p>
<div id="1e24da60" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's load a classification dataset - Titanic survival</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># This is a classic binary classification problem: survived or didn't survive</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>titanic <span class="op">=</span> pd.read_csv(<span class="st">'../data/titanic.csv'</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the target variable</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Target variable (Survived) value counts:"</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(titanic[<span class="st">'Survived'</span>].value_counts())</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Proportion survived: </span><span class="sc">{</span>titanic[<span class="st">'Survived'</span>]<span class="sc">.</span>mean()<span class="sc">:.2%}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Target variable (Survived) value counts:
Survived
0    549
1    342
Name: count, dtype: int64

Proportion survived: 38.38%</code></pre>
</div>
</div>
<p>Instead of predicting a number on a continuous scale, we’re predicting one of two discrete outcomes: 0 (didn’t survive) or 1 (survived). This is <strong>binary classification</strong>—the most common type.</p>
</section>
<section id="ch3-1-2" class="level3">
<h3 class="anchored" data-anchor-id="ch3-1-2">2.2 Types of Classification Problems</h3>
<p><strong>Binary Classification:</strong> Two possible outcomes (yes/no, spam/ham, fraud/legitimate)</p>
<ul>
<li>Titanic survival</li>
<li>Email spam detection</li>
<li>Loan default prediction</li>
<li>Disease diagnosis</li>
</ul>
<p><strong>Multi-class Classification:</strong> More than two categories</p>
<ul>
<li>Iris flower species (setosa, versicolor, virginica)</li>
<li>Handwritten digit recognition (0-9)</li>
<li>Customer segment classification</li>
<li>Image classification (cat, dog, bird, etc.)</li>
</ul>
<p>Most of this chapter focuses on binary classification since it’s simpler to visualize and understand. But the techniques extend naturally to multi-class problems.</p>
</section>
<section id="ch3-1-3" class="level3">
<h3 class="anchored" data-anchor-id="ch3-1-3">2.3 Why We Can’t Use Linear Regression</h3>
<p>You might be tempted to use linear regression for classification. Just predict the category as a number, right? Let’s see why that breaks:</p>
<div id="df458e31" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression, LogisticRegression</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare simple features</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>titanic_clean <span class="op">=</span> titanic[[<span class="st">'Age'</span>, <span class="st">'Survived'</span>, <span class="st">'Pclass'</span>, <span class="st">'Fare'</span>]].dropna()</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> titanic_clean[[<span class="st">'Age'</span>, <span class="st">'Pclass'</span>, <span class="st">'Fare'</span>]].values</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> titanic_clean[<span class="st">'Survived'</span>].values</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Try linear regression (WRONG!)</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>linear_model <span class="op">=</span> LinearRegression()</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>linear_model.fit(X_train, y_train)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>linear_pred <span class="op">=</span> linear_model.predict(X_test)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Predictions:'</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(linear_pred[:<span class="dv">5</span>])</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Classes:'</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_test[:<span class="dv">5</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Predictions:
[0.33588326 0.70372944 0.4655869  0.77416664 0.0881573 ]
Classes:
[0 1 1 1 0]</code></pre>
</div>
</div>
<p>See the problem? Linear regression gives us predictions like 0.73 or -0.15 or 1.42. But we need 0 or 1! We could threshold at 0.5, but linear regression makes no guarantee that predictions will be between 0 and 1. It’s using the wrong tool for the job.</p>
<p>Classification models are designed to output probabilities (values between 0 and 1) or direct class predictions. That’s why we need specialized algorithms.</p>
<hr>
</section>
</section>
<section id="ch3-3" class="level2">
<h2 class="anchored" data-anchor-id="ch3-3">3. Logistic Regression: The Foundation</h2>
<section id="ch3-2-1" class="level3">
<h3 class="anchored" data-anchor-id="ch3-2-1">3.1 From Linear to Logistic</h3>
<p>Logistic regression might sound like a regression technique, but don’t be fooled—it’s pure classification. The name comes from its history: it takes linear regression and transforms it to work for classification.</p>
<p>Here’s the key insight: instead of predicting the outcome directly, logistic regression predicts the <strong>probability</strong> of the positive class. It does this by taking a linear combination of features (just like linear regression) and passing it through the <strong>sigmoid function</strong>:</p>
<p><span class="math display">\[
\text{probability} = \frac{1}{1 + e^{-z}}
\]</span></p>
<p>where <span class="math inline">\(z\)</span> is the linear combination: <span class="math inline">\(z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ...\)</span></p>
<p>The sigmoid function has a beautiful property: it squashes any real number into the range (0, 1), making it perfect for probabilities.</p>
<div id="8487486b" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the sigmoid function</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>sigmoid <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>z))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>plt.plot(z, sigmoid, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Decision threshold (0.5)'</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'z (linear combination of features)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Probability of positive class'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'The Sigmoid Function: Turning Linear into Probability'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-7-output-1.png" width="815" height="528" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>When <span class="math inline">\(z = 0\)</span>, the probability is exactly 0.5. As <span class="math inline">\(z\)</span> increases, the probability approaches 1. As <span class="math inline">\(z\)</span> decreases, the probability approaches 0. The sigmoid smoothly transitions between these extremes.</p>
</section>
<section id="ch3-2-2" class="level3">
<h3 class="anchored" data-anchor-id="ch3-2-2">3.2 Fitting Logistic Regression</h3>
<p>Let’s fit a logistic regression model to predict Titanic survival:</p>
<div id="67b67802" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit logistic regression</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>log_model <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>, max_iter<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>log_model.fit(X_train, y_train)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predictions - both probabilities and classes</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> log_model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability of class 1</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>y_pred_class <span class="op">=</span> log_model.predict(X_test)  <span class="co"># Predicted class (0 or 1)</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the difference</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>comparison <span class="op">=</span> pd.DataFrame({</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'True'</span>: y_test,</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Prob_Survived'</span>: y_pred_proba,</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Predicted'</span>: y_pred_class</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>comparison.head(<span class="dv">10</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">True</th>
<th data-quarto-table-cell-role="th">Prob_Survived</th>
<th data-quarto-table-cell-role="th">Predicted</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>0</td>
<td>0.302603</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>1</td>
<td>0.741984</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>1</td>
<td>0.459317</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>1</td>
<td>0.791706</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>0</td>
<td>0.118771</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">5</th>
<td>1</td>
<td>0.707625</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">6</th>
<td>1</td>
<td>0.183988</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">7</th>
<td>1</td>
<td>0.202158</td>
<td>0</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">8</th>
<td>0</td>
<td>0.217621</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">9</th>
<td>0</td>
<td>0.261196</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Notice the two types of predictions:</p>
<ul>
<li><strong>Probabilities</strong> (from <code>predict_proba</code>): Values between 0 and 1 representing confidence</li>
<li><strong>Classes</strong> (from <code>predict</code>): Hard 0/1 decisions using a threshold (default 0.5)</li>
</ul>
<p>If the probability is above 0.5, we predict class 1 (survived). Otherwise, class 0 (didn’t survive). But you can adjust this threshold based on your problem—more on that later.</p>
<p>How can we evaluate this model’s performance? One simple way is to ask about the average probability for each different true class (i.e.&nbsp;average probabibility of survival for those who actually survived vs.&nbsp;those who didn’t).</p>
<div id="17a9d497" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate average probability for each true class</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>avg_prob_survived <span class="op">=</span> y_pred_proba[y_test <span class="op">==</span> <span class="dv">1</span>].mean()</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>avg_prob_not_survived <span class="op">=</span> y_pred_proba[y_test <span class="op">==</span> <span class="dv">0</span>].mean()</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Average probability for those who survived: </span><span class="sc">{</span>avg_prob_survived<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Average probability for those who didn't survive: </span><span class="sc">{</span>avg_prob_not_survived<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Average probability for those who survived: 0.505
Average probability for those who didn't survive: 0.339</code></pre>
</div>
</div>
<p>This is good, but it fails to capture the variability in predictions. A better approach would be to look at the distribution of probabilities for each class.</p>
<p>Let’s visualize this:</p>
<div id="562f7289" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>sns.histplot(data<span class="op">=</span>pd.DataFrame({<span class="st">'prob'</span>: y_pred_proba[y_test <span class="op">==</span> <span class="dv">1</span>], <span class="st">'class'</span>: <span class="st">'Survived'</span>}), x<span class="op">=</span><span class="st">'prob'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'Survived'</span>, bins<span class="op">=</span><span class="dv">20</span>, color<span class="op">=</span><span class="st">'blue'</span>, stat<span class="op">=</span><span class="st">'density'</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>sns.histplot(data<span class="op">=</span>pd.DataFrame({<span class="st">'prob'</span>: y_pred_proba[y_test <span class="op">==</span> <span class="dv">0</span>], <span class="st">'class'</span>: <span class="st">'Did not survive'</span>}), x<span class="op">=</span><span class="st">'prob'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'Did not survive'</span>, bins<span class="op">=</span><span class="dv">20</span>, color<span class="op">=</span><span class="st">'red'</span>, stat<span class="op">=</span><span class="st">'density'</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Probability of Survival'</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Distribution of Predicted Probabilities by True Outcome'</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-10-output-1.png" width="812" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We see that there are more people who survived with higher predicted probability of survival, and more people who died with lower predicted probability. This shows that our model is somewhat calibrated - it tends to give higher probabilities to those who actually survived and lower probabilities to those who didn’t.</p>
<p>We’ll learn more advanced techniques later, but this is a good starting point.</p>
</section>
<section id="ch3-3-3" class="level3">
<h3 class="anchored" data-anchor-id="ch3-3-3">3.3 Interpreting Coefficients</h3>
<p>Just like linear regression, logistic regression has coefficients. But the interpretation is different. In particular, we’re primarily concerned with the <strong>odds ratio</strong> of a coefficient, which is calculated as <span class="math inline">\(e^{\beta}\)</span> where <span class="math inline">\(\beta\)</span> is the coefficient. This tells us how the odds of the outcome change for a one-unit increase in the predictor.</p>
<div id="a98bcca7" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's use more features to make interpretation interesting</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [<span class="st">'Pclass'</span>, <span class="st">'Age'</span>, <span class="st">'SibSp'</span>, <span class="st">'Parch'</span>, <span class="st">'Fare'</span>]</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>titanic_features <span class="op">=</span> titanic[features <span class="op">+</span> [<span class="st">'Survived'</span>]].dropna()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>X_full <span class="op">=</span> titanic_features[features].values</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>y_full <span class="op">=</span> titanic_features[<span class="st">'Survived'</span>].values</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>X_train_full, X_test_full, y_train_full, y_test_full <span class="op">=</span> train_test_split(</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    X_full, y_full, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>log_model_full <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>, max_iter<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>log_model_full.fit(X_train_full, y_train_full)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Display coefficients</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>coef_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: features,</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coefficient'</span>: log_model_full.coef_[<span class="dv">0</span>],</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Odds_Ratio'</span>: np.exp(log_model_full.coef_[<span class="dv">0</span>])</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>coef_df</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Feature</th>
<th data-quarto-table-cell-role="th">Coefficient</th>
<th data-quarto-table-cell-role="th">Odds_Ratio</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>Pclass</td>
<td>-1.129795</td>
<td>0.323100</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>Age</td>
<td>-0.051874</td>
<td>0.949448</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>SibSp</td>
<td>-0.295579</td>
<td>0.744101</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>Parch</td>
<td>0.241379</td>
<td>1.273004</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>Fare</td>
<td>0.003802</td>
<td>1.003810</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p><strong>Odds ratio</strong> measures how much the odds of the outcome change for a one-unit increase in the predictor. An odds ratio greater than 1 indicates a positive association with the outcome, while an odds ratio less than 1 indicates a negative association.</p>
<p>For example, if <code>Fare</code> has an odds ratio of 1.5, it means that for every one-unit increase in fare, the odds of survival increase by 50%. If <code>Pclass</code> has an odds ratio of 0.7, it means that for every one-unit increase in class (higher class number), the odds of survival decrease by 30%. Here we see that:</p>
<ul>
<li>Increasing passenger class by 1 (e.g.&nbsp;3rd class -&gt; 2nd class) <em>decreased</em> the predicted probability of survival by about 68% <span class="math inline">\((1-0.323 = 0.677)\)</span>.</li>
<li>Increasing the age by 1 year slightly decreased (~5%) the predicted probability of survival.</li>
<li>Increasing the number of parents/children in the family (<code>Parch</code>) increased the predicted probability of survival by a whopping 27%!</li>
</ul>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Be careful about collinearity! Remember that last chapter we discussed how collinearity can lead to non-interpretable coefficients. Since logistic regression is simply performing linear regression under the hood, all those same caveats apply here. For example, it seems weird to say that people in higher passenger classes are <em>less likely</em> to survive. What’s probably going on is collinearity between <code>Pclass</code> and <code>Fare</code>, since both are essentially measuring the same thing (how much the ticket cost).</p>
</div>
</div>
<hr>
</section>
</section>
<section id="ch3-4" class="level2">
<h2 class="anchored" data-anchor-id="ch3-4">4. The Confusion Matrix: Understanding Errors</h2>
<section id="ch3-3-1" class="level3">
<h3 class="anchored" data-anchor-id="ch3-3-1">4.1 What Is a Confusion Matrix?</h3>
<p>When you make predictions, you’ll make mistakes. The confusion matrix breaks down exactly what kinds of mistakes you’re making. It’s a 2×2 table for binary classification:</p>
<div id="fcad9e7a" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predictions</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> log_model_full.predict(X_test_full)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confusion matrix</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test_full, y_pred)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize it</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, cbar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Not Survived'</span>, <span class="st">'Survived'</span>],</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Not Survived'</span>, <span class="st">'Survived'</span>])</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">True Negatives (TN): </span><span class="sc">{</span>cm[<span class="dv">0</span>, <span class="dv">0</span>]<span class="sc">}</span><span class="ss"> people died and we predicted they would die"</span>)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"False Positives (FP): </span><span class="sc">{</span>cm[<span class="dv">0</span>, <span class="dv">1</span>]<span class="sc">}</span><span class="ss"> people survived but we predicted they would die"</span>)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"False Negatives (FN): </span><span class="sc">{</span>cm[<span class="dv">1</span>, <span class="dv">0</span>]<span class="sc">}</span><span class="ss"> people died but we predicted they would survive"</span>)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"True Positives (TP): </span><span class="sc">{</span>cm[<span class="dv">1</span>, <span class="dv">1</span>]<span class="sc">}</span><span class="ss"> people survived and we predicted they would survive"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-12-output-1.png" width="658" height="528" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
True Negatives (TN): 74 people died and we predicted they would die
False Positives (FP): 13 people survived but we predicted they would die
False Negatives (FN): 30 people died but we predicted they would survive
True Positives (TP): 26 people survived and we predicted they would survive</code></pre>
</div>
</div>
<p><strong>The four quadrants:</strong></p>
<ul>
<li><strong>True Negatives (TN)</strong>: Correctly predicted “didn’t survive”</li>
<li><strong>False Positives (FP)</strong>: Predicted “survived” but actually didn’t (Type I error)</li>
<li><strong>False Negatives (FN)</strong>: Predicted “didn’t survive” but actually did (Type II error)</li>
<li><strong>True Positives (TP)</strong>: Correctly predicted “survived”</li>
</ul>
<p>Here we have shown the confusion matrix with the actual counts from our logistic regression model, such as 74 people, 13 people, etc. However, we’re often more interested in understanding how well our model predicted the correct values. For example, of the people who actually survived, what percentage did we predict will and won’t survive? In other words, we’re normalizing along the rows so that each rows adds up to 100%.</p>
<div id="80154ddf" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate row-wise percentages (normalize by actual positives)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>row_sums <span class="op">=</span> cm.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>recall_precision <span class="op">=</span> cm.astype(<span class="bu">float</span>) <span class="op">/</span> row_sums.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Display as a confusion matrix, with numbers formatted as percentages</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>sns.heatmap(recall_precision, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.0%'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, cbar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Not Survived'</span>, <span class="st">'Survived'</span>],</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Not Survived'</span>, <span class="st">'Survived'</span>])</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Normalized Confusion Matrix (Row-wise)'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-13-output-1.png" width="658" height="528" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here we see that, of the people who actually died, 87% were correctly predicted as having died (True Negative rate), while 13% were incorrectly predicted as having survived (False Positive rate). Similarly, of the people who actually survived, 92% were correctly predicted as having survived (True Positive rate), while 8% were incorrectly predicted as having died (False Negative rate).</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Displaying the data normalized relative to the true values is typically more useful than looking at the raw numbers. When converting to percentages we see that our model did quite well predicting people who will die, but very poorly predicting people who will survive. This suggests our model may be biased towards predicting death, which could be important to consider for real-world applications.</p>
</div>
</div>
</section>
<section id="ch3-3-2" class="level3">
<h3 class="anchored" data-anchor-id="ch3-3-2">4.2 Computing Metrics from the Confusion Matrix</h3>
<p>All the important classification metrics come directly from these four numbers:</p>
<p><strong>Accuracy</strong>: What percentage of all predictions were correct? <span class="math display">\[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\]</span></p>
<div id="708247e2" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> (cm[<span class="dv">0</span>, <span class="dv">0</span>] <span class="op">+</span> cm[<span class="dv">1</span>, <span class="dv">1</span>]) <span class="op">/</span> cm.<span class="bu">sum</span>()</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.699</code></pre>
</div>
</div>
<p><strong>Precision</strong>: When you predict positive, how often are you right? <span class="math display">\[
\text{Precision} = \frac{TP}{TP + FP}
\]</span></p>
<div id="cfb84e9e" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> cm[<span class="dv">1</span>, <span class="dv">1</span>] <span class="op">/</span> (cm[<span class="dv">1</span>, <span class="dv">1</span>] <span class="op">+</span> cm[<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision: </span><span class="sc">{</span>precision<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Precision: 0.667</code></pre>
</div>
</div>
<p><strong>Recall (Sensitivity)</strong>: Of all actual positives, how many did you find? <span class="math display">\[
\text{Recall} = \frac{TP}{TP + FN}
\]</span></p>
<div id="e9375945" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> cm[<span class="dv">1</span>, <span class="dv">1</span>] <span class="op">/</span> (cm[<span class="dv">1</span>, <span class="dv">1</span>] <span class="op">+</span> cm[<span class="dv">1</span>, <span class="dv">0</span>])</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall: </span><span class="sc">{</span>recall<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Recall: 0.464</code></pre>
</div>
</div>
<p><strong>F1 Score</strong>: Harmonic mean of precision and recall <span class="math display">\[
\text{F1} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\]</span></p>
<div id="f4405294" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (precision <span class="op">*</span> recall) <span class="op">/</span> (precision <span class="op">+</span> recall)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"F1 Score: </span><span class="sc">{</span>f1<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>F1 Score: 0.547</code></pre>
</div>
</div>
</section>
<section id="ch3-3-3" class="level3">
<h3 class="anchored" data-anchor-id="ch3-3-3">4.3 When Each Metric Matters</h3>
<p>Different problems care about different metrics:</p>
<p><strong>Use Accuracy when:</strong></p>
<ul>
<li>Classes are balanced</li>
<li>False positives and false negatives are equally costly</li>
<li>Example: Predicting coin flips (50/50 balanced, no asymmetric cost)</li>
</ul>
<p><strong>Use Precision when:</strong></p>
<ul>
<li>False positives are very costly</li>
<li>You want to be confident when you predict positive</li>
<li>Example: Spam detection (marking legitimate email as spam is very annoying, but one or two spam emails slipping through is acceptable)</li>
</ul>
<p><strong>Use Recall when:</strong></p>
<ul>
<li>False negatives are very costly</li>
<li>You want to catch all positive cases, even if it means some false alarms</li>
<li>Example: Disease screening (missing a sick patient with a life-threatening condition is much worse than telling a healthy patient that they are sick)</li>
</ul>
<p><strong>Use F1 Score when:</strong></p>
<ul>
<li>You want a balance between precision and recall</li>
<li>Classes are imbalanced</li>
<li>Example: Fraud detection (imbalanced, and both FP and FN have significant consequences)</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>There’s almost always a tradeoff between precision and recall. Increase one, and the other goes down. You need to decide which matters more for your specific problem.</p>
</div>
</div>
<p>Let’s see the full classification report:</p>
<div id="4cfc50cc" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_full, y_pred,</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>                          target_names<span class="op">=</span>[<span class="st">'Not Survived'</span>, <span class="st">'Survived'</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

Not Survived       0.71      0.85      0.77        87
    Survived       0.67      0.46      0.55        56

    accuracy                           0.70       143
   macro avg       0.69      0.66      0.66       143
weighted avg       0.69      0.70      0.69       143
</code></pre>
</div>
</div>
<p>This report shows precision, recall, and F1 for both classes, plus overall accuracy.</p>
<hr>
</section>
</section>
<section id="ch3-5" class="level2">
<h2 class="anchored" data-anchor-id="ch3-5">5. Decision Trees: Interpretable Non-Linear Classifiers</h2>
<section id="ch3-4-1" class="level3">
<h3 class="anchored" data-anchor-id="ch3-4-1">5.1 How Decision Trees Work</h3>
<p>Decision trees make predictions by asking a series of yes/no questions about the features. They split the data recursively based on feature values, creating a tree structure.</p>
<p>Here’s the beautiful part: decision trees are incredibly interpretable. You can literally draw out the decision-making process and explain it to anyone.</p>
<div id="ea5fa65c" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a simple decision tree</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>tree_model <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>tree_model.fit(X_train_full, y_train_full)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the tree</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>plot_tree(tree_model, feature_names<span class="op">=</span>features, class_names<span class="op">=</span>[<span class="st">'Not Survived'</span>, <span class="st">'Survived'</span>],</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>          filled<span class="op">=</span><span class="va">True</span>, fontsize<span class="op">=</span><span class="dv">10</span>, rounded<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Decision Tree for Titanic Survival'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-19-output-1.png" width="1507" height="783" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Each box shows:</p>
<ul>
<li>The question being asked (e.g., “Fare &lt;= 26.27?”)</li>
<li>The Gini impurity (measure of how mixed the classes are, discussed in the next section)</li>
<li>The number of samples reaching this node</li>
<li>The class distribution (number of zeros and ones)</li>
<li>The predicted class</li>
</ul>
</section>
<section id="ch3-4-2" class="level3">
<h3 class="anchored" data-anchor-id="ch3-4-2">5.2 Splitting Criteria: Gini vs Entropy</h3>
<p>Decision trees decide where to split by maximizing information gain. The most common criteria is the Gini impurity.</p>
<p><strong>Gini Impurity</strong>: Measures how often a randomly chosen element would be incorrectly classified <span class="math display">\[
\text{Gini} = 1 - \sum_{i=1}^{C} p_i^2
\]</span></p>
<p>where <span class="math inline">\(p_i\)</span> is the proportion of samples in class <span class="math inline">\(i\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Another criteria you’ll sometimes see is the Entropy, which is a measure of the amount of “disorder” or uncertainty. It is defined as <span class="math display">\[
\text{Entropy} = -\sum_{i=1}^{C} p_i \log_2(p_i)
\]</span> The actual values of Gini and entropy are often extremely similar, and are measuring similar things. Therefore, we’ll focus on Gini impurity in this textbook.</p>
</div>
</div>
<p>But what exactly is Gini computing? Let’s look at the tree we just created. In the first node, we see that there are 308 samples with class 0 (survived) and 154 samples with class 1 (did not survive). The Gini impurity is computed as follows: <span class="math display">\[
\text{Gini} = 1 - \displaystyle\sum_{i=1}^2 p_i^2 = 1 - \left(\frac{308}{462}\right)^2 - \left(\frac{154}{462}\right)^2 = \frac{4}{9} = 0.444
\]</span></p>
<p>Notice that this is exactly the Gini imprutiy stated in that node in the tree.</p>
<p>In general, how should we think about the value for Gini impurity?</p>
<p>Imagine that, in one of the nodes, there were 100 samples, and all of the samples were people who survived. Then the Gini impurity would be</p>
<p><span class="math display">\[
\text{Gini} = 1 - \displaystyle\sum_{i=0}^1 p_i^2 = 1 - \left(\frac{100}{100}\right)^2 - \left(\frac{0}{100}\right)^2 = 0
\]</span></p>
<p>Similarly, if all of the samples were people who did not survive, the Gini impurity would be</p>
<p><span class="math display">\[
\text{Gini} = 1 - \displaystyle\sum_{i=0}^1 p_i^2 = 1 - \left(\frac{0}{100}\right)^2 - \left(\frac{100}{100}\right)^2 = 0
\]</span></p>
<p>On the other hand, suppose there were a 50-50 split of the samples, with 50 samples of each class. Then the Gini impurity would be</p>
<p><span class="math display">\[
\text{Gini} = 1 - \displaystyle\sum_{i=0}^1 p_i^2 = 1 - \left(\frac{50}{100}\right)^2 - \left(\frac{50}{100}\right)^2 = \frac{1}{2} = 0.5
\]</span></p>
<p>Note how Gini impurity is small at the extremes (all samples have the same class), and bigger when the classes are more balanced. We can see this in the graph below, where the x-axis represents the proportion of class 1, and the y-axis represents the Gini impurity.</p>
<div id="d57f773f" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>, endpoint<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>gini <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (p<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>p)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>gini_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p'</span>: p,</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gini'</span>: gini</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>sns.lineplot(x<span class="op">=</span><span class="st">'p'</span>, y<span class="op">=</span><span class="st">'gini'</span>, data<span class="op">=</span>gini_df)</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Proportion of Class 1'</span>)</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Gini Impurity'</span>)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Gini Impurity in a Binary Classification Problem'</span>)</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-20-output-1.png" width="812" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>So, how is Gini impurity actually used to determine the splitting in decision trees? Our goal is to choose a split (i.e.&nbsp;a question) that best splits the data. For example, if we wanted to determine how well students will do in a class, asking whether they own a dog is a valid question, but won’t give me any additional information. On the other hand, if we ask if they regularly attend tutoring, we will get a much better idea of their performance.</p>
<p>In decision trees we use Gini impurity by calculating the Gini impurity for each possible split, and then choosing the split that has the smallest Gini impurity. This is because a smaller Gini impurity means that the split is better at separating the classes.</p>
</section>
<section id="ch3-4-3" class="level3">
<h3 class="anchored" data-anchor-id="ch3-4-3">5.3 Controlling Tree Depth: The Overfitting Problem</h3>
<p>Trees have a dangerous tendency: if you let them grow without limits, they’ll memorize the training data.</p>
<div id="40df4136" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare different tree depths</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>depths <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="va">None</span>]  <span class="co"># None means no limit</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>train_scores <span class="op">=</span> []</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>test_scores <span class="op">=</span> []</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> depth <span class="kw">in</span> depths:</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    tree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span>depth, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>    tree.fit(X_train_full, y_train_full)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    train_scores.append(tree.score(X_train_full, y_train_full))</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>    test_scores.append(tree.score(X_test_full, y_test_full))</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>depth_labels <span class="op">=</span> [<span class="bu">str</span>(d) <span class="cf">if</span> d <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">'Unlimited'</span> <span class="cf">for</span> d <span class="kw">in</span> depths]</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>plt.plot(depth_labels, train_scores, <span class="st">'o-'</span>, label<span class="op">=</span><span class="st">'Training Accuracy'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>plt.plot(depth_labels, test_scores, <span class="st">'s-'</span>, label<span class="op">=</span><span class="st">'Test Accuracy'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Maximum Tree Depth'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Tree Depth vs Performance: The Overfitting Story'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-21-output-1.png" width="823" height="528" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Classic overfitting! Training accuracy keeps increasing with depth, but test accuracy peaks and then plateaus or even decreases. The tree is memorizing noise in the training data.</p>
<p>We can see this concretely by printing out one of the decision paths in the deep trees:</p>
<div id="2ac6915f" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print one of the decision paths in the deep trees</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>tree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">20</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>tree.fit(X_train_full, y_train_full)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>sample_id <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>single_sample <span class="op">=</span> X_test_full[sample_id].reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>) <span class="co"># Reshape for single sample input</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the decision path for the single sample</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>node_indicator <span class="op">=</span> tree.decision_path(single_sample)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>node_indices <span class="op">=</span> node_indicator.indices[node_indicator.indptr[<span class="dv">0</span>]:node_indicator.indptr[<span class="dv">1</span>]]</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Get tree structure information for interpreting the path</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>children_left <span class="op">=</span> tree.tree_.children_left</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>children_right <span class="op">=</span> tree.tree_.children_right</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>feature <span class="op">=</span> tree.tree_.feature</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> tree.tree_.threshold</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> features</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Decision path for sample </span><span class="sc">{</span>sample_id<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> node_id <span class="kw">in</span> node_indices:</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> children_left[node_id] <span class="op">!=</span> children_right[node_id]:  <span class="co"># Check if it's a split node</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>        feature_index <span class="op">=</span> feature[node_id]</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>        threshold_value <span class="op">=</span> threshold[node_id]</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>        sample_feature_value <span class="op">=</span> single_sample[<span class="dv">0</span>, feature_index]</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> sample_feature_value <span class="op">&lt;=</span> threshold_value:</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>            decision <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>feature_names[feature_index]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>sample_feature_value<span class="sc">:.2f}</span><span class="ss">) &lt;= </span><span class="sc">{</span>threshold_value<span class="sc">:.2f}</span><span class="ss">"</span></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>            decision <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>feature_names[feature_index]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>sample_feature_value<span class="sc">:.2f}</span><span class="ss">) &gt; </span><span class="sc">{</span>threshold_value<span class="sc">:.2f}</span><span class="ss">"</span></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Node </span><span class="sc">{</span>node_id<span class="sc">}</span><span class="ss">: Split on </span><span class="sc">{</span>decision<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:  <span class="co"># It's a leaf node</span></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Node </span><span class="sc">{</span>node_id<span class="sc">}</span><span class="ss">: Leaf node reached (prediction: </span><span class="sc">{</span>tree<span class="sc">.</span>predict(single_sample)[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Decision path for sample 0:
  Node 0: Split on Fare (13.00) &lt;= 52.28
  Node 1: Split on Age (42.00) &gt; 5.50
  Node 11: Split on Pclass (2.00) &lt;= 2.50
  Node 12: Split on Age (42.00) &lt;= 42.50
  Node 13: Split on Fare (13.00) &gt; 12.31
  Node 23: Split on Pclass (2.00) &gt; 1.50
  Node 43: Split on Age (42.00) &gt; 15.00
  Node 45: Split on Age (42.00) &gt; 39.50
  Node 103: Split on Fare (13.00) &lt;= 26.50
  Node 104: Leaf node reached (prediction: 1)</code></pre>
</div>
</div>
<p>We start by asking reasonable seeming questions, but then asking more and more specific questions that seem unnecessary. For example, we ask if the persons age is:</p>
<ol type="1">
<li>Over 5.5</li>
<li>Less than 42.5</li>
<li>Over 15</li>
<li>Over 39.5</li>
</ol>
<p>Putting these together, we’ve asked if the person is between the ages of 39.5 and 42.5. That’s unnecessarily specific; do we really believe that a person being exactly 40 or 41 years old is so important? Instead, what’s happening is that our model is overfitting to the training data, and the results don’t generalize to the test data.</p>
<p><strong>Common hyperparameters to control overfitting:</strong></p>
<ul>
<li><code>max_depth</code>: Maximum depth of the tree</li>
<li><code>min_samples_split</code>: Minimum samples required to split a node</li>
<li><code>min_samples_leaf</code>: Minimum samples required at a leaf node</li>
<li><code>max_features</code>: Number of features to consider for each split</li>
</ul>
</section>
<section id="ch3-5-4" class="level3">
<h3 class="anchored" data-anchor-id="ch3-5-4">5.4 Feature Importance</h3>
<p>Trees can tell you which features are most important for making predictions:</p>
<div id="d0ee3822" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get feature importances</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>tree_final <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>tree_final.fit(X_train_full, y_train_full)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>importance_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: features,</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: tree_final.feature_importances_</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>}).sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>plt.barh(importance_df[<span class="st">'Feature'</span>], importance_df[<span class="st">'Importance'</span>])</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance from Decision Tree'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-23-output-1.png" width="834" height="528" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Feature importance represents how much each feature contributes to reducing impurity across all splits. Higher values mean more important features.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Feature importance can be calculated a number of different ways. One way is to take a column, randomly shuffle the values, and see how the impurity changes. If the impurity decreases, then the feature is important. This is called <strong>permutation feature importance</strong>.</p>
<p>For <code>DecisionTreeClassifier</code>, feature importance is calculated using <strong>impurity decrease</strong>. The impurity decrease is the difference in impurity before and after a split. The higher the impurity decrease, the more important the feature. For example, if a feature can be used to end up with nodes with small impurity, that means that feature can split the data into groups where one class is highly represented. Recall from above that impurity is a measure of how mixed up the classes are in a node. So if a feature can be used to end up with nodes with small impurity, that means that feature can split the data into groups where one class is highly represented. This is why the feature is important.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Different models calculate feature importance differently. However, they’re all trying to answer the same question: how much does this feature matter in terms of making predictions?</p>
<p>Don’t treat feature importance like a gold standard. It’s a tool for understanding your model, but it’s not a substitute for domain knowledge. Instead, you can often use feature importance to double-check your own understanding of the problem. If you believe a feature should be important, but it’s not showing up in the feature importance, then why not? Is it a problem with the model/data, or a problem with your understanding?</p>
</div>
</div>
<hr>
</section>
</section>
<section id="ch3-6" class="level2">
<h2 class="anchored" data-anchor-id="ch3-6">6. Random Forests: Ensemble Power</h2>
<section id="ch3-5-1" class="level3">
<h3 class="anchored" data-anchor-id="ch3-5-1">6.1 Why Ensembles Work</h3>
<p>Here’s a powerful idea: what if instead of training one tree, we trained many trees and let them vote?</p>
<p>Random Forests are one of the most successful examples. The key insight: many <strong>weak learners</strong> can combine to create a <strong>strong learner</strong>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Ensemble learning</strong> is the idea of combining many weak learners to create a strong learner. The key insight is that many weak learners can combine to create a strong learner.</p>
<p>By a <strong>weak learner</strong> we typically mean a very simple model, such as a decision tree with a depth of two. By a <strong>strong learner</strong> we typically mean a more complex model, such as a decision tree with a depth of ten.</p>
<p>The idea is that one large <em>complex</em> model may overfit to the training data, but many small <em>simple</em> models can combine to create a strong learner that generalizes well to the test data.</p>
<p>Random forests are one example of ensemble models, but we’ll learn more. Ensemble models are typically the gold standard in classical machine learning.</p>
</div>
</div>
<p><strong>How Random Forests work:</strong></p>
<ol type="1">
<li>Create many decision trees (e.g., 100 trees)</li>
<li>For each tree:
<ul>
<li>Sample a random subset of the data (bootstrapping)</li>
<li>At each split, only consider a random subset of features</li>
</ul></li>
<li>Make predictions by majority vote (classification), or by averaging probabilities (regression)</li>
</ol>
<p>The randomness in both samples and features ensures that trees are different from each other. After all, if we took all rows and all columns, each weak learner would likely be exactly the same. By sampling a random subset of the data and features, we ensure that each tree is different from the others.</p>
<p>When weak learners disagree, it’s often because they’re focusing on different aspects of the data. When they agree, you can be more confident.</p>
</section>
<section id="ch3-5-2" class="level3">
<h3 class="anchored" data-anchor-id="ch3-5-2">6.2 Fitting a Random Forest</h3>
<div id="cd7905db" class="cell" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit random forest</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">50</span>, max_depth<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train_full, y_train_full)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to single tree</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>tree_comparison <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>tree_comparison.fit(X_train_full, y_train_full)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Single Decision Tree:"</span>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Training Accuracy: </span><span class="sc">{</span>tree_comparison<span class="sc">.</span>score(X_train_full, y_train_full)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Test Accuracy: </span><span class="sc">{</span>tree_comparison<span class="sc">.</span>score(X_test_full, y_test_full)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Random Forest (50 trees):"</span>)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Training Accuracy: </span><span class="sc">{</span>rf_model<span class="sc">.</span>score(X_train_full, y_train_full)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Test Accuracy: </span><span class="sc">{</span>rf_model<span class="sc">.</span>score(X_test_full, y_test_full)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Single Decision Tree:
  Training Accuracy: 0.765
  Test Accuracy: 0.678

Random Forest (50 trees):
  Training Accuracy: 0.788
  Test Accuracy: 0.699</code></pre>
</div>
</div>
<p>Random forests typically achieve better generalization than single trees. The ensemble reduces overfitting through diversity.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Random forests are most useful for complex data with many columns, and with complex relationships between columns. For simple data with few columns, a single decision tree is often sufficient.</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>You may feel like “if one tree is good, then more trees are better!” This is true to an extent, but it comes with a tradeoff. When you train an ensemble model such as a random forest, you’re training many models. Each model takes time to train, and each model uses memory and compute time. Imagine training a single tree which takes ten seconds to train.</p>
<p>Now imagine training 50 trees, which would take 500 seconds to train, or nearly ten minutes! Combine this with hyperparameter tuning such as through a grid search, and you could easily be looking at an hour or more of training time. If the improvement in performance is large this may be worth it. But if your data is simple enough to get by with a simpler model, you can save hours of compute by going with a simpler model.</p>
</div>
</div>
</section>
<section id="ch3-5-3" class="level3">
<h3 class="anchored" data-anchor-id="ch3-5-3">6.3 Feature Importance in Random Forests</h3>
<p>Random forests also provide feature importances, but they’re generally more reliable than single trees because they average across many trees:</p>
<div id="603e05e5" class="cell" data-execution_count="24">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get feature importances from both models</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>tree_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: features,</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Decision Tree'</span>: tree_comparison.feature_importances_,</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Random Forest'</span>: rf_model.feature_importances_</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Melt the dataframe for plotting</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>importance_melted <span class="op">=</span> tree_importance.melt(</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    id_vars<span class="op">=</span><span class="st">'Feature'</span>,</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    var_name<span class="op">=</span><span class="st">'Model'</span>,</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    value_name<span class="op">=</span><span class="st">'Importance'</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort by average importance across both models</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>avg_importance <span class="op">=</span> tree_importance.set_index(<span class="st">'Feature'</span>).mean(axis<span class="op">=</span><span class="dv">1</span>).sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>importance_melted[<span class="st">'Feature'</span>] <span class="op">=</span> pd.Categorical(</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>    importance_melted[<span class="st">'Feature'</span>],</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>    categories<span class="op">=</span>avg_importance.index,</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>    ordered<span class="op">=</span><span class="va">True</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dodged bar chart</span></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>importance_melted, x<span class="op">=</span><span class="st">'Importance'</span>, y<span class="op">=</span><span class="st">'Feature'</span>, hue<span class="op">=</span><span class="st">'Model'</span>, palette<span class="op">=</span><span class="st">'Set2'</span>)</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance: Decision Tree vs Random Forest'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">'Model'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-25-output-1.png" width="951" height="566" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Random forest importances tend to be more stable because they’re averaged across many trees with different random subsets of data and features.</p>
</section>
<section id="ch3-6-4" class="level3">
<h3 class="anchored" data-anchor-id="ch3-6-4">6.4 Hyperparameter Tuning</h3>
<p>Random forests have several important hyperparameters:</p>
<div id="a1feb1f6" class="cell" data-execution_count="25">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test different numbers of trees</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>n_trees_list <span class="op">=</span> [<span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">75</span>, <span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>]</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> []</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_trees <span class="kw">in</span> n_trees_list:</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    rf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span>n_trees, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    rf.fit(X_train_full, y_train_full)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    scores.append(rf.score(X_test_full, y_test_full))</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>plt.plot(n_trees_list, scores, <span class="st">'o-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Trees'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Test Accuracy'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Random Forest Performance vs Number of Trees'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-26-output-1.png" width="831" height="528" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Performance typically improves with more trees, but you get diminishing returns. After a certain point (often 100-500 trees), adding more trees barely helps (or even leads to overfitting)but makes training slower. Use hyperparameter tuning to find the right number of trees. A typically starting point is 50 to 100 trees.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Random forests are often a great default choice for classification. They’re robust, handle non-linear relationships, require minimal hyperparameter tuning, and rarely overfit badly. When in doubt, try a random forest!</p>
</div>
</div>
<hr>
</section>
</section>
<section id="ch3-7" class="level2">
<h2 class="anchored" data-anchor-id="ch3-7">7. Support Vector Machines: Maximum Margin Classifiers</h2>
<section id="ch3-7-1" class="level3">
<h3 class="anchored" data-anchor-id="ch3-7-1">7.1 The Margin Concept</h3>
<p>Support Vector Machines (SVMs) have a beautiful geometric intuition: find the decision boundary that maximizes the distance to the nearest points from each class.</p>
<p>Think of it like this: if you’re drawing a line to separate two groups of points, you want it to be as far as possible from both groups. This gives you more confidence that future points will be classified correctly.</p>
<p>The “support vectors” are the points closest to the decision boundary—these are the critical points that define where the boundary goes.</p>
<div id="89088db2" class="cell" data-execution_count="26">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit SVM with linear kernel</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>svm_linear <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'linear'</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>svm_linear.fit(X_train_full, y_train_full)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"SVM Linear Kernel Accuracy: </span><span class="sc">{</span>svm_linear<span class="sc">.</span>score(X_test_full, y_test_full)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of support vectors: </span><span class="sc">{</span><span class="bu">len</span>(svm_linear.support_)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>SVM Linear Kernel Accuracy: 0.678
Number of support vectors: 374</code></pre>
</div>
</div>
</section>
<section id="ch3-7-2" class="level3">
<h3 class="anchored" data-anchor-id="ch3-7-2">7.2 The Kernel Trick</h3>
<p>Here’s where SVMs get really powerful: the <strong>kernel trick</strong>. By using different kernel functions, SVMs can create non-linear decision boundaries while still solving a linear problem in a higher-dimensional space.</p>
<p><strong>Common kernels:</strong></p>
<ul>
<li><strong>Linear</strong>: Creates straight boundaries (like logistic regression)</li>
<li><strong>RBF (Radial Basis Function)</strong>: Creates circular/curved boundaries</li>
<li><strong>Polynomial</strong>: Creates polynomial curves as boundaries</li>
</ul>
<div id="3b710429" class="cell" data-execution_count="27">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare different kernels</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>kernels <span class="op">=</span> [<span class="st">'linear'</span>, <span class="st">'rbf'</span>, <span class="st">'poly'</span>]</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>svm_models <span class="op">=</span> {}</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> kernel <span class="kw">in</span> kernels:</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    svm <span class="op">=</span> SVC(kernel<span class="op">=</span>kernel, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    svm.fit(X_train_full, y_train_full)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>    svm_models[kernel] <span class="op">=</span> svm</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>kernel<span class="sc">:8s}</span><span class="ss"> kernel - Test Accuracy: </span><span class="sc">{</span>svm<span class="sc">.</span>score(X_test_full, y_test_full)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>linear   kernel - Test Accuracy: 0.678
rbf      kernel - Test Accuracy: 0.615
poly     kernel - Test Accuracy: 0.629</code></pre>
</div>
</div>
</section>
<section id="ch3-6-3" class="level3">
<h3 class="anchored" data-anchor-id="ch3-6-3">6.3 Visualizing SVM Decision Boundaries</h3>
<p>Let’s see how different kernels create different boundaries. We’ll use California housing data, where different regions of the state have vastly different housing prices—a perfect example of non-linear geographic clustering:</p>
<div id="53182662" class="cell" data-execution_count="28">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load California housing data</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>california <span class="op">=</span> fetch_california_housing(as_frame<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>ca_df <span class="op">=</span> california.frame</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create binary classification: expensive (&gt;$3) vs affordable (&lt;=$3) houses</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Median house value is in $100,000s, so 3 = $300,000</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>ca_df[<span class="st">'expensive'</span>] <span class="op">=</span> (ca_df[<span class="st">'MedHouseVal'</span>] <span class="op">&gt;</span> <span class="fl">3.0</span>).astype(<span class="bu">int</span>)</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Use longitude and median house value for visualization</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Different parts of California have very different price patterns</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>X_viz <span class="op">=</span> ca_df[[<span class="st">'Latitude'</span>, <span class="st">'MedHouseVal'</span>]].values</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>y_viz <span class="op">=</span> ca_df[<span class="st">'expensive'</span>].values</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample for faster visualization (full dataset is 20k+ points)</span></span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>sample_idx <span class="op">=</span> np.random.choice(<span class="bu">len</span>(X_viz), size<span class="op">=</span><span class="dv">2000</span>, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>X_viz_raw <span class="op">=</span> X_viz[sample_idx]</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>y_viz <span class="op">=</span> y_viz[sample_idx]</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale features for SVM (IMPORTANT: SVMs are sensitive to feature scales)</span></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>X_viz <span class="op">=</span> scaler.fit_transform(X_viz_raw)</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>expensive <span class="op">=</span> y_viz <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a mesh for plotting decision boundaries (in scaled space)</span></span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>lon_range <span class="op">=</span> np.linspace(X_viz[:, <span class="dv">0</span>].<span class="bu">min</span>(), X_viz[:, <span class="dv">0</span>].<span class="bu">max</span>(), <span class="dv">100</span>)</span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>price_range <span class="op">=</span> np.linspace(X_viz[:, <span class="dv">1</span>].<span class="bu">min</span>(), X_viz[:, <span class="dv">1</span>].<span class="bu">max</span>(), <span class="dv">100</span>)</span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>lon_mesh, price_mesh <span class="op">=</span> np.meshgrid(lon_range, price_range)</span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a>mesh_points <span class="op">=</span> np.c_[lon_mesh.ravel(), price_mesh.ravel()]</span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit SVMs with different kernels on scaled data</span></span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a>svm_linear_viz <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'linear'</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a>svm_rbf_viz <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span><span class="st">'auto'</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a>svm_linear_viz.fit(X_viz, y_viz)</span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a>svm_rbf_viz.fit(X_viz, y_viz)</span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-42"><a href="#cb44-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Create predictions on mesh</span></span>
<span id="cb44-43"><a href="#cb44-43" aria-hidden="true" tabindex="-1"></a>mesh_linear <span class="op">=</span> svm_linear_viz.predict(mesh_points).reshape(lon_mesh.shape)</span>
<span id="cb44-44"><a href="#cb44-44" aria-hidden="true" tabindex="-1"></a>mesh_rbf <span class="op">=</span> svm_rbf_viz.predict(mesh_points).reshape(lon_mesh.shape)</span>
<span id="cb44-45"><a href="#cb44-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-46"><a href="#cb44-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot both</span></span>
<span id="cb44-47"><a href="#cb44-47" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">6</span>))</span>
<span id="cb44-48"><a href="#cb44-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-49"><a href="#cb44-49" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax, mesh_pred, title <span class="kw">in</span> <span class="bu">zip</span>(axes, [mesh_linear, mesh_rbf],</span>
<span id="cb44-50"><a href="#cb44-50" aria-hidden="true" tabindex="-1"></a>                                 [<span class="st">'SVM - Linear Kernel'</span>, <span class="st">'SVM - RBF Kernel'</span>]):</span>
<span id="cb44-51"><a href="#cb44-51" aria-hidden="true" tabindex="-1"></a>    ax.contourf(lon_mesh, price_mesh, mesh_pred, levels<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">'RdYlGn'</span>, alpha<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb44-52"><a href="#cb44-52" aria-hidden="true" tabindex="-1"></a>    ax.scatter(X_viz[expensive, <span class="dv">0</span>], X_viz[expensive, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'darkgreen'</span>, marker<span class="op">=</span><span class="st">'o'</span>,</span>
<span id="cb44-53"><a href="#cb44-53" aria-hidden="true" tabindex="-1"></a>               s<span class="op">=</span><span class="dv">20</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Expensive (&gt;$300k)'</span>)</span>
<span id="cb44-54"><a href="#cb44-54" aria-hidden="true" tabindex="-1"></a>    ax.scatter(X_viz[<span class="op">~</span>expensive, <span class="dv">0</span>], X_viz[<span class="op">~</span>expensive, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'darkred'</span>, marker<span class="op">=</span><span class="st">'x'</span>,</span>
<span id="cb44-55"><a href="#cb44-55" aria-hidden="true" tabindex="-1"></a>               s<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Affordable (≤$300k)'</span>)</span>
<span id="cb44-56"><a href="#cb44-56" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'Latitude'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb44-57"><a href="#cb44-57" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Median House Value ($100k)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb44-58"><a href="#cb44-58" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb44-59"><a href="#cb44-59" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb44-60"><a href="#cb44-60" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb44-61"><a href="#cb44-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-62"><a href="#cb44-62" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb44-63"><a href="#cb44-63" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-29-output-1.png" width="1527" height="566" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>See the difference? The linear kernel creates a straight boundary—it tries to separate expensive from affordable homes with a single line. But the RBF kernel creates smooth, curved boundaries that adapt to the geographic clustering of housing prices.</p>
<p>Notice how the RBF kernel captures the reality that certain geographic regions (coastal areas, Bay Area) command higher prices regardless of other factors. The curved decision boundary wraps around these high-value clusters much more naturally than a straight line ever could.</p>
</section>
<section id="ch3-7-4" class="level3">
<h3 class="anchored" data-anchor-id="ch3-7-4">7.4 When to Use SVMs</h3>
<p><strong>Strengths:</strong></p>
<ul>
<li>Effective in high-dimensional spaces</li>
<li>Memory efficient (only stores support vectors)</li>
<li>Flexible with different kernels</li>
<li>Works well with clear margin of separation</li>
</ul>
<p><strong>Weaknesses:</strong></p>
<ul>
<li>Slow to train on large datasets (doesn’t scale well beyond ~10,000 samples)</li>
<li>Requires feature scaling (sensitive to feature magnitudes)</li>
<li>Choosing the right kernel and hyperparameters can be tricky</li>
<li>Less interpretable than trees or logistic regression</li>
</ul>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always scale your features before using SVMs! They’re very sensitive to feature magnitudes. Use <code>StandardScaler</code> or <code>MinMaxScaler</code> from scikit-learn.</p>
</div>
</div>
<hr>
</section>
</section>
<section id="ch3-8" class="level2">
<h2 class="anchored" data-anchor-id="ch3-8">8. k-Nearest Neighbors: Simple but Powerful</h2>
<section id="ch3-7-1" class="level3">
<h3 class="anchored" data-anchor-id="ch3-7-1">8.1 The k-NN Algorithm</h3>
<p>k-Nearest Neighbors might be the simplest classification algorithm: to classify a new point, find the k closest training points and let them vote.</p>
<p>That’s it. No training phase. No learning parameters. Just store the data and compute distances when you need to make predictions.</p>
<div id="ae1e83bf" class="cell" data-execution_count="29">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit k-NN with k=5</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train_full, y_train_full)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"k-NN (k=5) Test Accuracy: </span><span class="sc">{</span>knn<span class="sc">.</span>score(X_test_full, y_test_full)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>k-NN (k=5) Test Accuracy: 0.650</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>KNN models sound like they should be simple. You simply find the k closest training points and let them vote. But in practice, they can be devilishly complex. For example, how do you measure “closeness”? In some data that may be simple, such as closeness in position or time. But what about data on students? What do we mean by the “closest students”? Closest in age? Same/similar major? Same/similar year in college? Are all of these equally important? Is one more important than another? How about closeness in courses taken? When should we consider two courses “close”?</p>
<p>All of these questions are enormously important in building effective KNN models, but they don’t have easy answers. KNN models, more than many others, require extensive testing to determine what works best.</p>
</div>
</div>
</section>
<section id="ch3-7-2" class="level3">
<h3 class="anchored" data-anchor-id="ch3-7-2">8.2 Choosing k: The Bias-Variance Tradeoff Again</h3>
<p>The value of k controls the bias-variance tradeoff:</p>
<ul>
<li><strong>Small k (e.g., k=1)</strong>: Very flexible, low bias, high variance (overfitting)</li>
<li><strong>Large k (e.g., k=100)</strong>: Smoother boundaries, high bias, low variance (underfitting)</li>
</ul>
<div id="a3cb1c92" class="cell" data-execution_count="30">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test different values of k</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>k_values <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>]</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>train_scores_knn <span class="op">=</span> []</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>test_scores_knn <span class="op">=</span> []</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_values:</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>    knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>k)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>    knn.fit(X_train_full, y_train_full)</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>    train_scores_knn.append(knn.score(X_train_full, y_train_full))</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>    test_scores_knn.append(knn.score(X_test_full, y_test_full))</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values, train_scores_knn, <span class="st">'o-'</span>, label<span class="op">=</span><span class="st">'Training Accuracy'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values, test_scores_knn, <span class="st">'s-'</span>, label<span class="op">=</span><span class="st">'Test Accuracy'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'k (number of neighbors)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'k-NN: Choosing k'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-31-output-1.png" width="823" height="528" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Notice the pattern: small k gives high training accuracy but may overfit. Moderate k (often 3-10) tends to work best, but hyperparameter tuning is needed to determine the best choice.</p>
</section>
<section id="ch3-8-3" class="level3">
<h3 class="anchored" data-anchor-id="ch3-8-3">8.3 Distance Metrics: How Do We Measure “Closeness”?</h3>
<p>The entire k-NN algorithm hinges on one question: how do you measure which points are “closest”? This isn’t just a technical detail—it fundamentally changes how your model behaves. Scikit-learn supports several distance metrics, and choosing the right one can dramatically affect performance.</p>
<p><strong>The most common distance metrics:</strong></p>
<ol type="1">
<li><p><strong>Euclidean distance</strong> (default): The straight-line distance between two points <span class="math display">\[d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}\]</span></p></li>
<li><p><strong>Manhattan distance</strong>: Sum of absolute differences (think of it as the number of city blocks between two locations, you can only walk horizontally or vertically) <span class="math display">\[d(x, y) = \sum_{i=1}^{n} |x_i - y_i|\]</span></p></li>
<li><p><strong>Minkowski distance</strong>: A mixture between Euclidean and Manhattan (p=1 is Manhattan, p=2 is Euclidean, but you can set p to any positive real number) <span class="math display">\[d(x, y) = \left(\sum_{i=1}^{n} |x_i - y_i|^p\right)^{1/p}\]</span></p></li>
<li><p><strong>Cosine distance</strong>: Measures angle between vectors (ignores the length of the vectors, and only cares about how far apart the directions they point are) <span class="math display">\[d(x, y) = 1 - \frac{x \cdot y}{||x|| \cdot ||y||}\]</span></p></li>
<li><p><strong>Hamming distance</strong>: Checks whether two values are equal or not, and computes the average number of features where two samples are equal <span class="math display">\[d(x, y) = \frac{1}{n}\sum_{i=1}^{n} \mathbb{1}(x_i \neq y_i)\]</span> where <span class="math inline">\(\mathbb{1}(x_i \neq y_i)\)</span> equals 1 if <span class="math inline">\(x_i \neq y_i\)</span> and 0 otherwise.</p></li>
</ol>
<p>Let’s see how different metrics perform on our Titanic data:</p>
<div id="bd50153b" class="cell" data-execution_count="31">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Test different distance metrics</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [<span class="st">'euclidean'</span>, <span class="st">'manhattan'</span>, <span class="st">'minkowski'</span>, <span class="st">'cosine'</span>, <span class="st">'hamming'</span>]</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>metric_scores <span class="op">=</span> {}</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> metric <span class="kw">in</span> metrics:</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Some metrics need additional parameters</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> metric <span class="op">==</span> <span class="st">'minkowski'</span>:</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>        knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>, metric<span class="op">=</span>metric, p<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>        knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>, metric<span class="op">=</span>metric)</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>    knn.fit(X_train_full, y_train_full)</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>    train_score <span class="op">=</span> knn.score(X_train_full, y_train_full)</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>    test_score <span class="op">=</span> knn.score(X_test_full, y_test_full)</span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>    metric_scores[metric] <span class="op">=</span> {<span class="st">'train'</span>: train_score, <span class="st">'test'</span>: test_score}</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(f"{metric:12s} - Train: {train_score:.3f}, Test: {test_score:.3f}")</span></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the metric and train/test score</span></span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a>plt.plot(metrics, [scores[<span class="st">'train'</span>] <span class="cf">for</span> scores <span class="kw">in</span> metric_scores.values()], <span class="st">'o-'</span>, label<span class="op">=</span><span class="st">'Training Accuracy'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a>plt.plot(metrics, [scores[<span class="st">'test'</span>] <span class="cf">for</span> scores <span class="kw">in</span> metric_scores.values()], <span class="st">'s-'</span>, label<span class="op">=</span><span class="st">'Test Accuracy'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Distance Metric'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb48-27"><a href="#cb48-27" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'k-NN: Choosing Distance Metric'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb48-28"><a href="#cb48-28" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb48-29"><a href="#cb48-29" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb48-30"><a href="#cb48-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-32-output-1.png" width="823" height="528" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Different metrics can give meaningfully different results! But which should you use?</p>
<p><strong>When to use each metric:</strong></p>
<p><strong>Euclidean distance</strong> (the default) works well when:</p>
<ul>
<li>All features have similar scales and units</li>
<li>You care about the actual geometric distance</li>
<li>Features are continuous numeric values</li>
<li>Example: Geographic coordinates (latitude/longitude), physical measurements</li>
</ul>
<p><strong>Manhattan distance</strong> works well when:</p>
<ul>
<li>Features represent different units that shouldn’t be combined quadratically</li>
<li>You have grid-like data (think city blocks, not “as the crow flies”)</li>
<li>You want to reduce the influence of outliers (no squaring!)</li>
<li>Example: Recommender systems, routing/navigation problems</li>
</ul>
<p><strong>Cosine distance</strong> works well when:</p>
<ul>
<li>You care about direction/orientation, not magnitude</li>
<li>Data is high-dimensional and sparse</li>
<li>Feature scales vary wildly</li>
<li>Example: Text data (word counts), recommendation systems with user ratings</li>
</ul>
<p><strong>Hamming distance</strong> works well when:</p>
<ul>
<li>You have categorical or binary features</li>
<li>All features are equally important (no scaling needed)</li>
<li>You want to count how many features differ, not by how much</li>
<li>Example: DNA sequences, binary feature vectors, categorical data (after one-hot encoding)</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Hamming distance treats all feature differences equally. If Feature A differs by 0.1 and Feature B differs by 10, Hamming sees both as “different.” It’s perfect for categorical data where “different is different” regardless of magnitude, but not ideal for continuous numeric features where the size of the difference matters.</p>
</div>
</div>
<p>Let’s visualize how these different metrics create different neighborhoods. We’ll use a simple 2D example:</p>
<div id="126f2ab3" class="cell" data-execution_count="32">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> NearestNeighbors</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a simple 2D point to query</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>query_point <span class="op">=</span> np.array([[<span class="fl">2.0</span>, <span class="fl">3.0</span>]])</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create some sample points</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>sample_points <span class="op">=</span> np.random.rand(<span class="dv">20</span>, <span class="dv">2</span>) <span class="op">*</span> <span class="dv">5</span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Find 5 nearest neighbors using different metrics</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">5</span>))</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax, metric <span class="kw">in</span> <span class="bu">zip</span>(axes, [<span class="st">'euclidean'</span>, <span class="st">'manhattan'</span>, <span class="st">'cosine'</span>]):</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find neighbors</span></span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>    nbrs <span class="op">=</span> NearestNeighbors(n_neighbors<span class="op">=</span><span class="dv">5</span>, metric<span class="op">=</span>metric)</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>    nbrs.fit(sample_points)</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>    distances, indices <span class="op">=</span> nbrs.kneighbors(query_point)</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot</span></span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>    ax.scatter(sample_points[:, <span class="dv">0</span>], sample_points[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'lightgray'</span>,</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>               s<span class="op">=</span><span class="dv">100</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, label<span class="op">=</span><span class="st">'Other points'</span>)</span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a>    ax.scatter(sample_points[indices[<span class="dv">0</span>], <span class="dv">0</span>], sample_points[indices[<span class="dv">0</span>], <span class="dv">1</span>],</span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>               c<span class="op">=</span><span class="st">'blue'</span>, s<span class="op">=</span><span class="dv">100</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'5 nearest neighbors'</span>)</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>    ax.scatter(query_point[<span class="dv">0</span>, <span class="dv">0</span>], query_point[<span class="dv">0</span>, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a>               marker<span class="op">=</span><span class="st">'*'</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Query point'</span>)</span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw lines to nearest neighbors</span></span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> indices[<span class="dv">0</span>]:</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>        ax.plot([query_point[<span class="dv">0</span>, <span class="dv">0</span>], sample_points[idx, <span class="dv">0</span>]],</span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a>                [query_point[<span class="dv">0</span>, <span class="dv">1</span>], sample_points[idx, <span class="dv">1</span>]],</span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a>                <span class="st">'b--'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'</span><span class="sc">{</span>metric<span class="sc">.</span>capitalize()<span class="sc">}</span><span class="ss"> Distance'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'Feature 1'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Feature 2'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb49-36"><a href="#cb49-36" aria-hidden="true" tabindex="-1"></a>    ax.legend(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-39"><a href="#cb49-39" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb49-40"><a href="#cb49-40" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-33-output-1.png" width="1719" height="470" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>See how the same query point has different nearest neighbors depending on the metric? Euclidean forms circular neighborhoods, Manhattan forms diamond-shaped neighborhoods, and cosine focuses on angular similarity.</p>
</section>
<section id="ch3-7-4" class="level3">
<h3 class="anchored" data-anchor-id="ch3-7-4">8.4 Mixing Metrics: Different Features Need Different Distances</h3>
<p>Here’s a critical insight that’s often overlooked: <strong>real datasets have different types of features, and each type needs its own distance metric</strong>.</p>
<p>Think about internet service provider (ISP) customer data and predicting churn:</p>
<ul>
<li><strong>Internet Service</strong>: Categorical (DSL, Fiber optic, No internet). We want to know if two customers have the same service type—not treat “DSL” as somehow numerically between “No internet” and “Fiber optic”</li>
<li><strong>Contract type</strong>: Categorical (Month-to-month, One year, Two year). Either the same or different.</li>
<li><strong>Gender</strong>: Categorical (Male, Female). Same or different.</li>
<li><strong>Monthly Charges</strong>: Continuous numeric variable. A customer paying $50/month is more similar to one paying $55 than to one paying $100.</li>
<li><strong>Tenure</strong>: Continuous numeric variable. The actual difference in months matters.</li>
</ul>
<p>The problem? When you call <code>KNeighborsClassifier(metric='euclidean')</code>, it treats ALL features the same way! It computes Euclidean distance on internet service type and contract (treating categorical values as if they were numbers) just like it does on monthly charges and tenure.</p>
<p><strong>The solution: Create a custom distance metric that treats different feature types appropriately.</strong></p>
<p>For example, you could define a custom distance function that:</p>
<ul>
<li>Uses <strong>Hamming distance</strong> (equality check) for categorical features (Internet Service, Contract, Gender)</li>
<li>Uses <strong>Euclidean distance</strong> for continuous features (Monthly Charges, Tenure)</li>
</ul>
<p>These can be difficult to implement by hand, so working together with an AI coding assistant is the way to go.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Why does this matter?</strong></p>
<p>Imagine comparing two ISP customers: - Customer A: DSL, Month-to-month contract, Male, $50/month, 12 months tenure - Customer B: Fiber optic, Month-to-month contract, Male, $52/month, 14 months tenure</p>
<p>With pure Euclidean distance, if internet service is encoded as DSL=0 and Fiber optic=1, the difference in service type contributes “1” to the distance calculation, just like a $1/month price difference. But internet service type is categorical! Having DSL vs Fiber optic is a fundamental categorical difference—not a numeric one.</p>
<p>With the mixed metric, we recognize that internet service differs (Hamming distance = 1), contract and gender are the same (Hamming distance = 0 for each), and then we properly compute Euclidean distance for the continuous features (monthly charges, tenure) where the magnitude of difference actually matters.</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>When building custom distance metrics:</strong></p>
<ol type="1">
<li><strong>Identify feature types first</strong>: Which are categorical? Which are continuous?</li>
<li><strong>Scale continuous features</strong>: Use StandardScaler before computing distances</li>
<li><strong>Don’t scale categorical features</strong>: They represent discrete categories, not magnitudes</li>
<li><strong>Test your metric</strong>: Does it give sensible distances for sample pairs?</li>
<li><strong>Weight carefully</strong>: You might want to weight categorical and continuous distances differently</li>
</ol>
<p>The custom metric approach requires more work, but it’s often worth it for datasets with mixed feature types!</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>How to choose a distance metric:</strong></p>
<ol type="1">
<li><strong>Start with Euclidean</strong> (the default) - it works well in most cases</li>
<li><strong>Try Hamming</strong> if you have categorical features that have no obvious ordering</li>
<li><strong>Try Manhattan</strong> if you have outliers or features on very different scales</li>
<li><strong>Try Cosine</strong> if your data is high-dimensional or sparse (like text data)</li>
<li><strong>Use cross-validation</strong> to compare metrics on your specific dataset</li>
<li><strong>Always scale your features</strong> before using distance-based methods!</li>
</ol>
<p>The “best” metric depends on your data and problem. Don’t just accept the default—experiment and use validation performance to guide your choice.</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Feature scaling is critical for k-NN!</strong> If one feature ranges from 0-1 and another ranges from 0-1000, the second feature will dominate the distance calculation. Always use <code>StandardScaler</code> or <code>MinMaxScaler</code> before fitting k-NN models.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train_scaled, y_train)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="ch3-7-5" class="level3">
<h3 class="anchored" data-anchor-id="ch3-7-5">8.5 When to Use k-NN</h3>
<p><strong>Strengths:</strong></p>
<ul>
<li>Simple to understand and implement</li>
<li>No training phase (though this is also a weakness)</li>
<li>Naturally handles multi-class problems</li>
<li>Can capture complex patterns</li>
</ul>
<p><strong>Weaknesses:</strong></p>
<ul>
<li>Slow prediction (has to compute distances to all training points)</li>
<li>Memory intensive (stores all training data)</li>
<li>Requires feature scaling</li>
<li>Choosing k can be tricky</li>
<li>Determining appropriate distance metric can be complex</li>
</ul>
<hr>
</section>
</section>
<section id="ch3-9" class="level2">
<h2 class="anchored" data-anchor-id="ch3-9">9. ROC Curves and AUC: Comparing Models</h2>
<section id="ch3-9-1" class="level3">
<h3 class="anchored" data-anchor-id="ch3-9-1">9.1 The ROC Curve</h3>
<p>So far we’ve been using a fixed threshold (0.5) to convert probabilities to class predictions. But what if we tried different thresholds?</p>
<p>The <strong>ROC curve</strong> (Receiver Operating Characteristic) shows model performance across all possible thresholds. It plots:</p>
<ul>
<li><strong>True Positive Rate (TPR)</strong> = Recall = TP / (TP + FN)</li>
<li><strong>False Positive Rate (FPR)</strong> = FP / (FP + TN)</li>
</ul>
<div id="361ccac7" class="cell" data-execution_count="33">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, roc_auc_score</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get probability predictions from logistic regression</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>y_proba_log <span class="op">=</span> log_model_full.predict_proba(X_test_full)[:, <span class="dv">1</span>]</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute ROC curve</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_test_full, y_proba_log)</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute AUC (Area Under the Curve)</span></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>auc <span class="op">=</span> roc_auc_score(y_test_full, y_proba_log)</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'Logistic Regression (AUC = </span><span class="sc">{</span>auc<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Random Classifier (AUC = 0.5)'</span>)</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate (Recall)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ROC Curve'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-34-output-1.png" width="666" height="676" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Interpreting the ROC curve:</strong></p>
<ul>
<li>The diagonal line represents a random classifier (flip a coin)</li>
<li>The closer your curve sticks to the top-left corner, the better</li>
<li>AUC (Area Under the Curve) summarizes performance in one number</li>
<li>AUC = 1.0: Perfect classifier</li>
<li>AUC = 0.5: Random guessing</li>
<li>AUC &lt; 0.5: Worse than random (you’re predicting backwards!)</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why is an ROC curve “sticking to the top-left corner” a good thing? The top-left corner means we have essentially zero false positives, and high true positives.</p>
</div>
</div>
</section>
<section id="ch3-8-2" class="level3">
<h3 class="anchored" data-anchor-id="ch3-8-2">9.2 Comparing Multiple Models with ROC</h3>
<p>Let’s compare all our models on the same ROC plot:</p>
<div id="90d75fcc" class="cell" data-execution_count="34">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get probabilities from all models</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>models_for_roc <span class="op">=</span> {</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Logistic Regression'</span>: log_model_full,</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Decision Tree'</span>: tree_final,</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Random Forest'</span>: rf_model,</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SVM (RBF)'</span>: SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, probability<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>).fit(X_train_full, y_train_full),</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'k-NN'</span>: knn</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, model <span class="kw">in</span> models_for_roc.items():</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(model, <span class="st">"predict_proba"</span>):</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>        y_proba <span class="op">=</span> model.predict_proba(X_test_full)[:, <span class="dv">1</span>]</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># SVM without probability=True would fail here</span></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>        y_proba <span class="op">=</span> model.predict_proba(X_test_full)[:, <span class="dv">1</span>]</span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, _ <span class="op">=</span> roc_curve(y_test_full, y_proba)</span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a>    auc <span class="op">=</span> roc_auc_score(y_test_full, y_proba)</span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a>    plt.plot(fpr, tpr, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> (AUC = </span><span class="sc">{</span>auc<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, label<span class="op">=</span><span class="st">'Random (AUC = 0.5)'</span>)</span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ROC Curves: Model Comparison'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-35-output-1.png" width="815" height="676" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This visualization makes it easy to compare models at a glance. The model with the highest AUC is typically performing best across all thresholds.</p>
</section>
<section id="ch3-8-3" class="level3">
<h3 class="anchored" data-anchor-id="ch3-8-3">9.3 When to Use ROC/AUC</h3>
<p><strong>Use ROC/AUC when:</strong></p>
<ul>
<li>You want threshold-independent evaluation</li>
<li>Classes are relatively balanced</li>
<li>You care about ranking (who’s more likely to be positive?)</li>
</ul>
<p><strong>Don’t use ROC/AUC when:</strong></p>
<ul>
<li>Classes are severely imbalanced</li>
<li>You have a specific threshold constraint</li>
<li>You care more about absolute performance at one threshold</li>
</ul>
<hr>
</section>
</section>
<section id="ch3-10" class="level2">
<h2 class="anchored" data-anchor-id="ch3-10">10. Class Imbalance: The Real-World Problem</h2>
<section id="ch3-9-1" class="level3">
<h3 class="anchored" data-anchor-id="ch3-9-1">10.1 Why Class Imbalance Matters</h3>
<p>The truth is, most real-world classification problems have imbalanced classes. Fraud detection? Maybe 0.1% of transactions are fraud. Disease diagnosis? Most patients who show up a a hospital don’t have a specific disease. Email spam? While we all get spam, that’s not the majority of our email.</p>
<p>Class imbalance breaks naive approaches. For example, suppose we had data where 1% of the people had a given rare disease. If we built a model that predicted everyone as not having the disease, we would be 99% accurate. But that’s not a very useful model!</p>
</section>
<section id="ch3-9-2" class="level3">
<h3 class="anchored" data-anchor-id="ch3-9-2">10.2 Detecting Class Imbalance</h3>
<p>Always check class balance before building models. Let’s look at a real example: predicting whether a song on Spotify will become a “viral hit” (popularity score above 80). Most songs don’t go viral, so this is naturally imbalanced:</p>
<div id="d99ced96" class="cell" data-execution_count="35">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Spotify data and create an imbalanced classification problem</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>spotify_df <span class="op">=</span> pd.read_csv(<span class="st">'../data/spotify.csv'</span>)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create binary target: viral hit (popularity &gt; 80) vs not</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>spotify_df[<span class="st">'viral_hit'</span>] <span class="op">=</span> (spotify_df[<span class="st">'popularity'</span>] <span class="op">&gt;</span> <span class="dv">80</span>).astype(<span class="bu">int</span>)</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Select numeric features for our model</span></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>spotify_features <span class="op">=</span> [<span class="st">'danceability'</span>, <span class="st">'energy'</span>, <span class="st">'loudness'</span>, <span class="st">'speechiness'</span>,</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'acousticness'</span>, <span class="st">'instrumentalness'</span>, <span class="st">'liveness'</span>, <span class="st">'valence'</span>, <span class="st">'tempo'</span>]</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop rows with missing values</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>spotify_clean <span class="op">=</span> spotify_df[spotify_features <span class="op">+</span> [<span class="st">'viral_hit'</span>]].dropna()</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>X_imbalanced <span class="op">=</span> spotify_clean[spotify_features].values</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>y_imbalanced <span class="op">=</span> spotify_clean[<span class="st">'viral_hit'</span>].values</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Split imbalanced data</span></span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a>X_train_imb, X_test_imb, y_train_imb, y_test_imb <span class="op">=</span> train_test_split(</span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a>    X_imbalanced, y_imbalanced, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loaded Spotify dataset with </span><span class="sc">{</span><span class="bu">len</span>(y_imbalanced)<span class="sc">}</span><span class="ss"> songs"</span>)</span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Viral hits (popularity &gt; 90): </span><span class="sc">{</span>y_imbalanced<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Regular songs: </span><span class="sc">{</span>(y_imbalanced <span class="op">==</span> <span class="dv">0</span>)<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loaded Spotify dataset with 42663 songs
Viral hits (popularity &gt; 90): 125
Regular songs: 42538</code></pre>
</div>
</div>
<p>Now let’s check the class balance:</p>
<div id="886eefb1" class="cell" data-execution_count="36">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check balance with seaborn</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_class_balance(y, name<span class="op">=</span><span class="st">"Dataset"</span>):</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>    counts <span class="op">=</span> pd.Series(y).value_counts()</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame({<span class="st">'Class'</span>: [<span class="st">'Class 0'</span>, <span class="st">'Class 1'</span>], <span class="st">'Count'</span>: counts})</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>    sns.barplot(x<span class="op">=</span><span class="st">'Class'</span>, y<span class="op">=</span><span class="st">'Count'</span>, data<span class="op">=</span>df)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>    plt.title(name)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>check_class_balance(y_imbalanced, <span class="st">"Spotify Viral Hit Dataset - Highly imbalanced"</span>)</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>check_class_balance(y_full, <span class="st">"Titanic Dataset - Fairly balanced"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-37-output-1.png" width="610" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-37-output-2.png" width="593" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Rules of thumb:</strong></p>
<ul>
<li>Ratio &lt; 2:1 → Probably not a problem</li>
<li>Ratio 2:1 to 10:1 → Moderate imbalance, be careful with metrics</li>
<li>Ratio &gt; 10:1 → Severe imbalance, definitely needs special handling</li>
</ul>
</section>
<section id="ch3-9-3" class="level3">
<h3 class="anchored" data-anchor-id="ch3-9-3">10.3 Handling Class Imbalance: Class Weights</h3>
<p>One simple approach: tell the model to weight the minority class more heavily during training. Many models have the ability to assign weights to different classes, using the <code>class_weight</code> parameter with a value of <code>'balanced'</code>.</p>
<p>First, let’s fit a “naive” model that ignores the imbalance:</p>
<div id="19cc9ac8" class="cell" data-execution_count="37">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a naive model (ignores imbalance)</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>naive_model <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>, max_iter<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>naive_model.fit(X_train_imb, y_train_imb)</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>y_pred_naive <span class="op">=</span> naive_model.predict(X_test_imb)</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>conf_mat <span class="op">=</span> confusion_matrix(y_test_imb, y_pred_naive)</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot normalized confusion matrix (normalize by row)</span></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>conf_mat_norm <span class="op">=</span> conf_mat.astype(<span class="st">'float'</span>) <span class="op">/</span> conf_mat.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_mat_norm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.2f'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>,</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Not Viral'</span>, <span class="st">'Viral'</span>],</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Not Viral'</span>, <span class="st">'Viral'</span>])</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True'</span>)</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Naive Model Confusion Matrix'</span>)</span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-38-output-1.png" width="425" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Notice how every single song is predicted as being not popular. That’s because the model gets “better” predictions by predicting the majority class (not viral) for every song.</p>
<p>Now let’s compare with a model that uses class weights:</p>
<div id="f0acec14" class="cell" data-execution_count="38">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit with class weights</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>weighted_model <span class="op">=</span> LogisticRegression(class_weight<span class="op">=</span><span class="st">'balanced'</span>, random_state<span class="op">=</span><span class="dv">42</span>, max_iter<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>weighted_model.fit(X_train_imb, y_train_imb)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>y_pred_weighted <span class="op">=</span> weighted_model.predict(X_test_imb)</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot normalized confusion matrix (normalize by row)</span></span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>conf_mat_weighted <span class="op">=</span> confusion_matrix(y_test_imb, y_pred_weighted)</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>conf_mat_weighted_norm <span class="op">=</span> conf_mat_weighted.astype(<span class="st">'float'</span>) <span class="op">/</span> conf_mat_weighted.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_mat_weighted_norm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.2f'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>,</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Not Viral'</span>, <span class="st">'Viral'</span>],</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Not Viral'</span>, <span class="st">'Viral'</span>])</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True'</span>)</span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Model with balanced class weights Confusion Matrix'</span>)</span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-39-output-1.png" width="444" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The <code>class_weight='balanced'</code> parameter automatically weights classes inversely proportional to their frequency. This forces the model to pay more attention to minority class errors, and results in a fairly strong model with good precision and recall.</p>
</section>
<section id="ch3-9-4" class="level3">
<h3 class="anchored" data-anchor-id="ch3-9-4">10.4 Handling Class Imbalance: Resampling</h3>
<p>Another approach: change the data itself so that it’s balanced.</p>
<p><strong>Undersampling</strong>: Remove examples from majority class</p>
<p><strong>Oversampling</strong>: Duplicate examples from minority class</p>
<p><strong>SMOTE</strong> (Synthetic Minority Over-sampling Technique): Create synthetic minority class examples</p>
<div id="212418aa" class="cell" data-execution_count="39">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> SMOTE</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.under_sampling <span class="im">import</span> RandomUnderSampler</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply SMOTE</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>smote <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>X_train_smote, y_train_smote <span class="op">=</span> smote.fit_resample(X_train_imb, y_train_imb)</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original training set:"</span>)</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>check_class_balance(y_train_imb, <span class="st">"Before SMOTE"</span>)</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">After SMOTE:"</span>)</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>check_class_balance(y_train_smote, <span class="st">"After SMOTE"</span>)</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Train on balanced data</span></span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>smote_model <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>, max_iter<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>smote_model.fit(X_train_smote, y_train_smote)</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on original imbalanced test set</span></span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>y_pred_smote <span class="op">=</span> smote_model.predict(X_test_imb)</span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Model trained on SMOTE data:"</span>)</span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>conf_mat_smote <span class="op">=</span> confusion_matrix(y_test_imb, y_pred_smote)</span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a>conf_mat_smote_norm <span class="op">=</span> conf_mat_smote.astype(<span class="st">'float'</span>) <span class="op">/</span> conf_mat_smote.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_mat_smote_norm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.2f'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>,</span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Not Viral'</span>, <span class="st">'Viral'</span>],</span>
<span id="cb58-27"><a href="#cb58-27" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Not Viral'</span>, <span class="st">'Viral'</span>])</span>
<span id="cb58-28"><a href="#cb58-28" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb58-29"><a href="#cb58-29" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True'</span>)</span>
<span id="cb58-30"><a href="#cb58-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'SMOTE Model Confusion Matrix'</span>)</span>
<span id="cb58-31"><a href="#cb58-31" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original training set:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-40-output-2.png" width="610" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
After SMOTE:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-40-output-4.png" width="610" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Model trained on SMOTE data:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-40-output-6.png" width="425" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>When using resampling techniques like SMOTE, only resample the training data! Never resample the test set—you want to evaluate on the natural class distribution.</p>
</div>
</div>
</section>
<section id="ch3-9-5" class="level3">
<h3 class="anchored" data-anchor-id="ch3-9-5">10.5 Choosing Metrics for Imbalanced Data</h3>
<p>With imbalanced data, accuracy is almost always misleading. Use:</p>
<ul>
<li><strong>Precision</strong>: When false positives are costly</li>
<li><strong>Recall</strong>: When false negatives are costly</li>
<li><strong>F1 Score</strong>: When you want a balance</li>
<li><strong>AUC-ROC</strong>: Threshold-independent, but can be optimistic with severe imbalance</li>
</ul>
<hr>
</section>
</section>
<section id="ch3-10" class="level2">
<h2 class="anchored" data-anchor-id="ch3-10">11. Comparing All Models: A Practical Guide</h2>
<section id="ch3-10-1" class="level3">
<h3 class="anchored" data-anchor-id="ch3-10-1">11.1 Model Selection Framework</h3>
<p>With so many classification algorithms, how do you choose? Here’s a practical framework:</p>
<p><strong>Start with logistic regression if:</strong></p>
<ul>
<li>You need interpretability (coefficients matter)</li>
<li>You want fast training and prediction</li>
<li>You suspect linear decision boundaries</li>
<li>You have limited data</li>
</ul>
<p><strong>Use decision trees if:</strong></p>
<ul>
<li>You need maximum interpretability (show the tree to stakeholders)</li>
<li>Features are on different scales (trees don’t need scaling)</li>
<li>You have non-linear relationships</li>
<li>You’re okay with potential overfitting</li>
</ul>
<p><strong>Use random forests if:</strong></p>
<ul>
<li>You want robust performance without much tuning</li>
<li>You have enough data (hundreds or thousands of samples)</li>
<li>You don’t need interpretability</li>
<li>You want feature importance estimates</li>
</ul>
<p><strong>Use SVMs if:</strong></p>
<ul>
<li>You have high-dimensional data (many features)</li>
<li>You have clear margin of separation</li>
<li>You’re willing to spend time tuning hyperparameters</li>
<li>Dataset is not too large (&lt; 10,000 samples)</li>
</ul>
<p><strong>Use k-NN if:</strong></p>
<ul>
<li>You have small datasets</li>
<li>You don’t need fast predictions</li>
<li>You have low-to-moderate dimensions</li>
<li>Decision boundaries are very irregular</li>
</ul>
</section>
<section id="ch3-10-2" class="level3">
<h3 class="anchored" data-anchor-id="ch3-10-2">11.2 Complete Model Comparison</h3>
<p>Let’s do a comprehensive comparison:</p>
<div id="ed08a0db" class="cell" data-execution_count="40">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define models</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>comparison_models <span class="op">=</span> {</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Logistic Regression'</span>: LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>, max_iter<span class="op">=</span><span class="dv">1000</span>),</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Decision Tree'</span>: DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Random Forest'</span>: RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SVM (RBF)'</span>: SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, probability<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'k-NN (k=5)'</span>: KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare on Titanic data using cross-validation</span></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> []</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, model <span class="kw">in</span> comparison_models.items():</span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Cross-validation scores</span></span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>    cv_scores <span class="op">=</span> cross_val_score(model, X_full, y_full, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit and evaluate</span></span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>    model.fit(X_train_full, y_train_full)</span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>    y_pred_comp <span class="op">=</span> model.predict(X_test_full)</span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute metrics</span></span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_score, recall_score, f1_score</span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a>    results.append({</span>
<span id="cb62-27"><a href="#cb62-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Model'</span>: name,</span>
<span id="cb62-28"><a href="#cb62-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">'CV Accuracy (mean)'</span>: cv_scores.mean(),</span>
<span id="cb62-29"><a href="#cb62-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">'CV Accuracy (std)'</span>: cv_scores.std(),</span>
<span id="cb62-30"><a href="#cb62-30" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Test Accuracy'</span>: accuracy_score(y_test_full, y_pred_comp),</span>
<span id="cb62-31"><a href="#cb62-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Precision'</span>: precision_score(y_test_full, y_pred_comp),</span>
<span id="cb62-32"><a href="#cb62-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Recall'</span>: recall_score(y_test_full, y_pred_comp),</span>
<span id="cb62-33"><a href="#cb62-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">'F1 Score'</span>: f1_score(y_test_full, y_pred_comp)</span>
<span id="cb62-34"><a href="#cb62-34" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb62-35"><a href="#cb62-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-36"><a href="#cb62-36" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(results).set_index(<span class="st">'Model'</span>)</span>
<span id="cb62-37"><a href="#cb62-37" aria-hidden="true" tabindex="-1"></a>results_df</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CV Accuracy (mean)</th>
<th data-quarto-table-cell-role="th">CV Accuracy (std)</th>
<th data-quarto-table-cell-role="th">Test Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
<th data-quarto-table-cell-role="th">F1 Score</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Model</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">Logistic Regression</th>
<td>0.689077</td>
<td>0.042540</td>
<td>0.699301</td>
<td>0.666667</td>
<td>0.464286</td>
<td>0.547368</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Decision Tree</th>
<td>0.715719</td>
<td>0.041416</td>
<td>0.678322</td>
<td>0.619048</td>
<td>0.464286</td>
<td>0.530612</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">Random Forest</th>
<td>0.703103</td>
<td>0.037517</td>
<td>0.664336</td>
<td>0.600000</td>
<td>0.428571</td>
<td>0.500000</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">SVM (RBF)</th>
<td>0.666699</td>
<td>0.072339</td>
<td>0.615385</td>
<td>0.513514</td>
<td>0.339286</td>
<td>0.408602</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">k-NN (k=5)</th>
<td>0.659795</td>
<td>0.059218</td>
<td>0.650350</td>
<td>0.565217</td>
<td>0.464286</td>
<td>0.509804</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="ch3-10-3" class="level3">
<h3 class="anchored" data-anchor-id="ch3-10-3">11.3 Visualizing Model Performance</h3>
<div id="49503d12" class="cell" data-execution_count="41">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot comparison</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [<span class="st">'Test Accuracy'</span>, <span class="st">'Precision'</span>, <span class="st">'Recall'</span>, <span class="st">'F1 Score'</span>]</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>results_df[metrics].plot(kind<span class="op">=</span><span class="st">'bar'</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>), rot<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Score'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Model Comparison Across Metrics'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">'lower right'</span>)</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="fl">0.5</span>, <span class="fl">1.0</span>)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter-3-classification_files/figure-html/cell-42-output-1.png" width="1143" height="565" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="ch3-10-4" class="level3">
<h3 class="anchored" data-anchor-id="ch3-10-4">11.4 The Importance of Context</h3>
<p>There’s no single “best” model. The right choice depends on:</p>
<ol type="1">
<li><strong>Problem requirements</strong>: Speed? Interpretability? Accuracy?</li>
<li><strong>Data characteristics</strong>: Size? Dimensionality? Imbalance?</li>
<li><strong>Computational resources</strong>: Training time? Prediction time? Memory?</li>
<li><strong>Business context</strong>: Cost of errors? Regulatory requirements?</li>
</ol>
<p>A model with 90% accuracy might be useless if it misses the 10% that actually matters. A model with 75% accuracy might be perfect if it catches the critical cases.</p>
<hr>
</section>
</section>
<section id="ch3-summary" class="level2">
<h2 class="anchored" data-anchor-id="ch3-summary">Summary</h2>
<p>You’ve learned the fundamentals of classification and explored five major approaches. Let’s recap the key insights.</p>
<p><strong>Classification is fundamentally different from regression.</strong> You’re predicting categories, not continuous values. This changes everything: the algorithms, the evaluation metrics, the challenges you’ll face. Linear regression is the wrong tool. You need classifiers designed to output probabilities or discrete predictions.</p>
<p><strong>Each algorithm has a sweet spot.</strong> Logistic regression for speed and interpretability with linear boundaries. Decision trees for maximum explainability. Random forests for robust performance without much tuning. SVMs for high-dimensional data with clear margins. k-NN for small datasets with complex local patterns. There’s no universal best—context matters.</p>
<p><strong>The confusion matrix is your diagnostic tool.</strong> True positives, false positives, true negatives, false negatives—these four numbers tell you exactly where your model succeeds and fails. Every metric (accuracy, precision, recall, F1) derives from them. Master confusion matrices and you can navigate any classification problem.</p>
<p><strong>Accuracy alone is almost always insufficient.</strong> Especially with imbalanced data, accuracy can be completely misleading. You need to understand precision (when I predict positive, am I usually right?) and recall (of all actual positives, how many do I catch?). The tradeoff between them depends on your specific problem’s costs. Medical diagnosis? Maximize recall. Spam detection? Maybe maximize precision. There’s no one-size-fits-all answer.</p>
<p><strong>ROC curves let you compare models across all thresholds.</strong> Instead of committing to 0.5 as your decision threshold, ROC curves show performance across all possible thresholds. AUC summarizes this in one number. Higher is better.</p>
<p><strong>Class imbalance is the norm, not the exception.</strong> Fraud detection, disease diagnosis, rare event prediction—most interesting real-world problems have imbalanced classes. Naive models will just predict the majority class and claim victory with high accuracy. You need to detect imbalance (check value counts!), use appropriate metrics (forget accuracy, use F1 or AUC), and handle it properly (class weights, SMOTE, or other resampling techniques).</p>
<p><strong>Visualization helps build intuition.</strong> Decision boundaries, ROC curves, confusion matrix heatmaps—these aren’t just pretty pictures. They help you understand what your model is actually doing. A model might have great accuracy but terrible decision boundaries. Visualization helps you see problems that metrics alone might hide.</p>
<p>Classification is a core data science skill. You’ll use it constantly: predicting customer churn, detecting fraud, diagnosing diseases, filtering spam, recommending products, identifying images. The algorithms you’ve learned here are the foundation. Master them, understand their tradeoffs, and you’ll be equipped to tackle real classification problems.</p>
<p>Use your brain. That’s what it’s there for.</p>
<hr>
</section>
<section id="ch3-practice" class="level2">
<h2 class="anchored" data-anchor-id="ch3-practice">Practice Exercises</h2>
<ol type="1">
<li><p><strong>Build and Compare Classifiers</strong>: Using the Titanic dataset (or another binary classification dataset), fit all five classifier types (Logistic Regression, Decision Tree, Random Forest, SVM, k-NN). Create confusion matrices for each and compare their precision, recall, and F1 scores. Which performs best? Why do you think that is?</p></li>
<li><p><strong>ROC Curve Comparison</strong>: Using the same dataset from Exercise 1, plot ROC curves for all five models on the same figure. Which model has the highest AUC? Does this match the model with the best accuracy? Why or why not?</p></li>
<li><p><strong>Hyperparameter Tuning</strong>: Take a Decision Tree classifier and experiment with different values of <code>max_depth</code> (try 1, 3, 5, 10, 20, None). Plot training and test accuracy vs depth. At what depth does overfitting become apparent? How can you tell?</p></li>
<li><p><strong>Feature Importance Analysis</strong>: Fit a Random Forest on a classification dataset with multiple features. Extract and visualize feature importances. Which features are most predictive? Now remove the top feature and retrain. How much does performance drop?</p></li>
<li><p><strong>Class Imbalance Challenge</strong>: Create an imbalanced dataset (90% class 0, 10% class 1) using <code>make_classification</code>. Fit a naive logistic regression and check its confusion matrix. Then try three approaches to handle the imbalance: class weights, random oversampling, and SMOTE. Which works best? Use F1 score to compare.</p></li>
<li><p><strong>Threshold Tuning</strong>: Using logistic regression with <code>predict_proba()</code>, manually try different classification thresholds (0.3, 0.5, 0.7, 0.9). For each threshold, compute precision and recall. Plot precision vs recall as you vary the threshold. Explain the tradeoff you observe.</p></li>
</ol>
<hr>
</section>
<section id="ch3-additional-resources" class="level2">
<h2 class="anchored" data-anchor-id="ch3-additional-resources">Additional Resources</h2>
<ul>
<li><a href="https://scikit-learn.org/stable/supervised_learning.html#supervised-learning">Scikit-learn Classification Documentation</a> - Official docs for all classifiers</li>
<li><a href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc">Understanding the ROC Curve</a> - Google’s ML crash course on ROC/AUC</li>
<li><a href="https://imbalanced-learn.org/">Imbalanced-learn Documentation</a> - Handling imbalanced datasets with Python</li>
<li><a href="https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/">Confusion Matrix Guide</a> - Clear explanation of TP, FP, TN, FN</li>
<li><a href="https://towardsdatascience.com/precision-vs-recall-386cf9f89488">Precision vs Recall</a> - When to optimize for which metric</li>
<li><a href="https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm">Random Forests Explained</a> - Original paper by Leo Breiman (creator of random forests)</li>
<li><a href="https://www.youtube.com/watch?v=efR1C6CvhmE">SVM Visualization</a> - StatQuest video explaining SVMs visually</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/paulsavala\.github\.io\/math-3339-intro-data-science-with-llms\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>
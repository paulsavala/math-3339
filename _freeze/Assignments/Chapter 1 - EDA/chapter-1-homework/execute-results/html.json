{
  "hash": "b27bb2c82148f90567edb0fed89c2af6",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Chapter 1 Homework: AI-Assisted Coding and Exploratory Data Analysis\"\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    code-fold: false\n    theme: cosmo\njupyter: python3\n---\n\n## Instructions\n\nThis homework is meant to be completed **with AI assistance** (such as an in-browser LLM like ChatGPT, and/or using a CLI like Claude Code) to practice scaling your data exploration work.\n\nFor all questions, submit:\n\n1. Your code (in a `.py` file or Jupyter notebook)\n2. All visualizations generated\n3. Written answers to interpretation questions (can be in markdown or comments)\n4. The prompts you used with the AI assistant(s)\n\n### Dataset\n\nYou'll be working with the **California Housing Dataset**, which contains information about California census block groups. You should load it using `sklearn.datasets.fetch_california_housing` and then create a Pandas DataFrame with the feature columns plus the target.\n\n**Data Set Characteristics:**\n\n- Number of Instances: 20640\n- Number of Attributes: 8 numeric, predictive attributes and the target\n\n**Attribute Information:**\n\n- `MedInc`: Median income in block group\n- `HouseAge`: Median house age in block group\n- `AveRooms`: Average number of rooms per household\n- `AveBedrms`: Average number of bedrooms per household\n- `Population`: Block group population\n- `AveOccup`: Average number of household members\n- `Latitude`: Block group latitude\n- `Longitude`: Block group longitude\n\n**Target Variable:**\n\n- `MedHouseVal`: Median house value for California districts, expressed in hundreds of thousands of dollars ($100,000).\n\n**Notes:**\n\n- This dataset comes from the StatLib repository: https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n- This dataset was derived from the 1990 U.S. census and uses one row per census block group.\n- A block group typically has a population of 600 to 3,000 people.\n- Since rooms/bedrooms are averages per household, some values can be surprisingly large.\n- Missing Attribute Values: None\n\nUse the following code to load the dataset into a DataFrame named `df`:\n\n::: {#5601d1d9 .cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.datasets import fetch_california_housing\nimport pandas as pd\n\nhousing = fetch_california_housing(as_frame=True)\ndf = housing.frame\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>MedHouseVal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8.3252</td>\n      <td>41.0</td>\n      <td>6.984127</td>\n      <td>1.023810</td>\n      <td>322.0</td>\n      <td>2.555556</td>\n      <td>37.88</td>\n      <td>-122.23</td>\n      <td>4.526</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.3014</td>\n      <td>21.0</td>\n      <td>6.238137</td>\n      <td>0.971880</td>\n      <td>2401.0</td>\n      <td>2.109842</td>\n      <td>37.86</td>\n      <td>-122.22</td>\n      <td>3.585</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.2574</td>\n      <td>52.0</td>\n      <td>8.288136</td>\n      <td>1.073446</td>\n      <td>496.0</td>\n      <td>2.802260</td>\n      <td>37.85</td>\n      <td>-122.24</td>\n      <td>3.521</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.6431</td>\n      <td>52.0</td>\n      <td>5.817352</td>\n      <td>1.073059</td>\n      <td>558.0</td>\n      <td>2.547945</td>\n      <td>37.85</td>\n      <td>-122.25</td>\n      <td>3.413</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.8462</td>\n      <td>52.0</td>\n      <td>6.281853</td>\n      <td>1.081081</td>\n      <td>565.0</td>\n      <td>2.181467</td>\n      <td>37.85</td>\n      <td>-122.25</td>\n      <td>3.422</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n---\n\n## Questions\n\n### Question 0:\n- Which LLM assistant(s) did you use? Be specific. For example, \"I used ChatGPT in the browser\", or \"I used Claude Code in the terminal\". \n\n### Question 1 (5 points)\n\nUse AI to create a comprehensive data profile that includes:\n\n- Summary statistics for ALL numerical columns (including the target)\n- A report on missing values (which columns, how many, what percentage)\n- Identification of potential outliers in numerical columns (using percentile method: values below 1st or above 99th percentile)\n\n**Deliverables:**\n\n- The prompt(s) you used\n- The code generated\n- The output/report\n\n---\n\n### Question 2 (5 points)\n\nPrompt the AI to create a function that generates a complete set of univariate visualizations for the dataset. This should include:\n\n- Histograms for all numerical columns (including the target)\n- All plots should be saved to a folder called `univariate_plots/`\n- Each plot should have proper labels and titles\n\nRun the function and submit all generated plots along with your code.\n\n**Deliverables:**\n\n- The prompt(s) you used\n- The code\n- All generated visualizations\n\n---\n\n### Question 3 (5 points)\n\nUse AI to create a pair plot (using `sns.pairplot()`) showing relationships between key numerical variables: `MedHouseVal`, `MedInc`, `HouseAge`, and `AveRooms`. Color the points by **binned** `MedHouseVal` (for example, low/medium/high using `pd.qcut`).\n\nBased on the pair plot, answer:\n\n- Which pair of variables shows the strongest visual relationship?\n- Are there any variables that don't seem to relate to `MedHouseVal`?\n- Do you notice any differences across the low/medium/high value groups?\n\n**Deliverables:**\n\n- The prompt(s) you used\n- The pair plot visualization\n- Your written interpretation (3-4 sentences)\n\n---\n\n### Question 4 (6 points)\n\nPrompt the AI to create a function that compares `MedHouseVal` distributions across different subgroups. Specifically:\n\n- Compare `MedHouseVal` by **binned `MedInc`** (e.g., low/medium/high)\n- Compare `MedHouseVal` by **binned `HouseAge`** (e.g., 0-10, 10-30, 30+)\n- Compare `MedHouseVal` by **latitude region** (e.g., North/Central/South using cutoffs)\n- Generate both statistical summaries AND visualizations (box plots or violin plots)\n\nRun this function and write 2-3 paragraphs interpreting the results. What insights did you gain about what drives housing values?\n\n**Deliverables:**\n\n- The prompt(s) you used\n- The code\n- All visualizations\n- Your written interpretation\n\n---\n\n### Question 5 (6 points)\n\nAsk the AI to help you identify potential outliers in the `MedHouseVal` column. Your approach should:\n\n- Define outliers as values below the 1st percentile or above the 99th percentile\n- Create visualizations showing the distribution with outliers highlighted\n- Display summary statistics for the full dataset and for data excluding outliers\n- Investigate the outliers: are they data errors or legitimate expensive/cheap houses?\n\nHow many potential outliers did you identify? Should they be removed, or do they represent legitimate data points? Justify your answer.\n\n**Deliverables:**\n\n- The prompt(s) you used\n- The code\n- Visualizations showing outliers\n- Written analysis (4-5 sentences)\n\n---\n\n### Question 6 (6 points)\n\nUse AI to create a comprehensive test suite for the housing dataset. Your test suite should include at least 5 unit tests that check:\n\n- Data types are correct\n- No negative values in columns where they don't make sense (`MedInc`, `AveRooms`, `AveBedrms`, `Population`, `AveOccup`)\n- Reasonable ranges for geographic coordinates (Latitude between 32 and 42, Longitude between -125 and -114)\n- Reasonable ranges for `HouseAge` (e.g., 0 to 100)\n- No duplicate rows\n\nRun all tests and report which (if any) failed.\n\n**Deliverables:**\n\n- The prompt(s) you used\n- The complete test suite code\n- Test results\n\n---\n\n### Question 7 (5 points)\n\nPrompt the AI to create multiple scatter plots exploring the relationship between `MedHouseVal` and other numerical variables. You should generate:\n\n- `MedHouseVal` vs. `MedInc` (colored by `Latitude`)\n- `MedHouseVal` vs. `HouseAge` (colored by binned `HouseAge`)\n- `MedHouseVal` vs. `AveRooms` (with a trend line)\n- `MedHouseVal` vs. `AveOccup` (colored by `Longitude`)\n\nFor each plot, write 1-2 sentences describing what you observe.\n\n**Deliverables:**\n\n- The prompt(s) you used\n- All scatter plots\n- Your written observations\n\n---\n\n### Question 8 (6 points)\n\nUse AI to create a function that systematically explores how `MedHouseVal` relates to **engineered categorical variables** created from numeric columns. For each engineered categorical variable, the function should:\n\n- Create a bar plot showing average `MedHouseVal` by category\n- Generate a box plot showing the distribution of `MedHouseVal` across categories\n- Calculate and display summary statistics (mean, median, count) for each category\n- Save all plots to a folder called `categorical_analysis/`\n\nUse at least three engineered categories such as:\n\n- `MedInc` binned into low/medium/high\n- `HouseAge` binned into 3-4 groups\n- `Latitude` binned into North/Central/South\n\nRun this function and write a paragraph identifying which engineered categories seem most important in determining house values.\n\n**Deliverables:**\n\n- The prompt(s) you used\n- The function code\n- All generated visualizations\n- Your written analysis\n\n---\n\n### Question 9 (6 points)\n\nUse AI to create a function that performs a complete exploratory data analysis for ANY numerical column in the dataset. The function should:\n\n- Take a DataFrame and column name as inputs\n- Generate: histogram, box plot, and summary statistics\n- Identify potential outliers using percentiles (values below 1st or above 99th percentile)\n- Create a markdown-formatted report with findings\n- Save all plots to a specified folder\n\nRun this function on three different columns: `MedHouseVal`, `MedInc`, and `AveRooms`.\n\n**Deliverables:**\n\n- The prompt(s) you used\n- The function code\n- All generated visualizations\n- The markdown reports for each column\n\n---\n\n### Question 10 (7 points)\n\nFor this final question, ask the AI to help you create a comprehensive EDA report. This should be a multi-page visualization that includes:\n\n- Overall dataset summary (rows, columns, missing values)\n- Distribution plots for key numerical variables\n- Correlation analysis\n- `MedHouseVal` analysis by different engineered categorical variables\n- Any interesting patterns or anomalies you discovered\n\nWrite a 1-page executive summary (300-400 words) that you would present to a stakeholder who doesn't know anything about data science. Explain:\n\n- What the dataset contains\n- Key findings from your analysis\n- What factors seem most important in determining house values\n- Any data quality issues or limitations\n- Recommendations for next steps\n\n**Deliverables:**\n\n- The prompt(s) you used\n- All visualizations in your EDA report\n- Your executive summary\n- Reflection: How did using AI change your approach to this comprehensive analysis compared to doing it by hand?\n\n---\n\n## Submission Guidelines\n\nSubmit a ZIP file containing one folder for each problem. Within each folder you should have one file for each of the following:\n\n1. **Code files:** All `.py` files or Jupyter notebooks\n2. **Visualizations folder:** All plots and charts generated\n3. **Written responses:** A single document (PDF or Markdown) with all your written answers, interpretations, and AI prompts used\n4. **Data:** Include your cleaned/modified datasets if you created any\n\n",
    "supporting": [
      "chapter-1-homework_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}